[
{
	"uri": "//localhost:1313/4-mongodb-atlas/4.1-atlas-setup/",
	"title": "MongoDB Atlas Setup &amp; Configuration",
	"tags": [],
	"description": "",
	"content": "MongoDB Atlas Setup \u0026amp; Configuration Overview Trong phần này, chúng ta sẽ thiết lập MongoDB Atlas cluster từ đầu, cấu hình network access, database users, và thiết lập các tính năng cần thiết cho e-learning platform. Bạn sẽ học cách tạo cluster, cấu hình security, và thiết lập monitoring.\nPrerequisites MongoDB Atlas Account Setup Required Services\nMongoDB Atlas Account: Active account với billing enabled Cloud Provider: AWS, Google Cloud, hoặc Azure Network Access: IP whitelist hoặc VPC peering Database Access: Users và roles configuration Account Requirements\nAccount Type: Free Tier hoặc Paid Billing Method: Credit card hoặc invoice Cloud Provider: AWS (recommended for integration) Region: [Select closest to your application] Step 1: Create MongoDB Atlas Account Account Registration 1. Navigate to MongoDB Atlas\n# Mở browser và truy cập # https://cloud.mongodb.com # Click \u0026#34;Try Free\u0026#34; hoặc \u0026#34;Sign Up\u0026#34; 2. Account Creation\nEmail: [Your email address] Password: [Strong password] Account name: [Your organization name] - Example: Esoclusty E-Learning - Used for project organization - Can be changed later 3. Email Verification\nVerification Process: - Check email inbox - Click verification link - Complete account setup - Access Atlas dashboard Step 2: Create Atlas Project Project Setup 1. Create New Project\nProject Name: E-Learning Platform - Descriptive name for organization - Can contain multiple clusters - Used for resource grouping - Example: \u0026#34;Esoclusty E-Learning Platform\u0026#34; Project Owner: [Your email] - Primary administrator - Can invite team members - Manages billing and access 2. Project Configuration\nProject Settings: - Name: E-Learning Platform - Description: MongoDB clusters for e-learning application - Tags: - Environment: Production - Project: E-Learning - Team: Development Step 3: Create MongoDB Cluster Cluster Configuration 1. Build a Database\nDatabase Type: MongoDB Version: 7.0 (Latest stable) - Latest features và security updates - Long-term support available - Compatibility with Spring Boot 2. Cloud Provider \u0026amp; Region\nCloud Provider: AWS - Best integration with existing AWS services - VPC peering support - Consistent billing Region Selection: [Select closest to your application] - Consider latency requirements - Consider compliance requirements - Consider cost differences - Example: US East (N. Virginia) Cluster Tier Selection Free Tier (M0)\nCluster Tier: M0 Sandbox - Use Case: Development và testing - Storage: 512 MB - RAM: Shared - vCPU: Shared - Cost: Free - Limitations: No dedicated resources Paid Tiers (M2+)\nDevelopment Environment: - M2: $9/month, 2 GB storage - M5: $25/month, 5 GB storage Production Environment: - M10: $57/month, 10 GB storage - M20: $114/month, 20 GB storage - M30: $171/month, 30 GB storage Cluster Settings Cluster Name\nCluster Name: elearning-cluster-[env] - Example: elearning-cluster-prod - Descriptive và unique - Environment indicator - Easy identification Additional Settings\nCluster Settings: - Backup: Enabled (recommended) - Provider Settings: Default - Cluster Tier: [Selected tier] - Cloud Provider: AWS - Region: [Selected region] Step 4: Configure Network Access IP Access List 1. Network Access Configuration\nAccess Method: IP Access List - Simple và straightforward - Good for development - Easy to manage - Suitable for small teams 2. IP Address Configuration\nIP Addresses: - Office Network: 192.168.1.0/24 - Home Network: [Your home IP]/32 - Development Server: [Server IP]/32 - Public Access: 0.0.0.0/0 (not recommended for production) Comment: [Description for each IP range] - Example: \u0026#34;Office network - Development team\u0026#34; - Example: \u0026#34;Home office - Personal development\u0026#34; VPC Peering (Advanced) AWS VPC Peering\nVPC Peering Setup: - AWS VPC: vpc-12345678 - Atlas VPC: vpc-atlas-87654321 - Route Tables: Configure routing - Security Groups: Allow MongoDB access - Benefits: Private, secure connection Step 5: Configure Database Access Database Users 1. Create Database User\nUser Configuration: - Username: elearning_user - Password: [Strong password] - Database: admin - Roles: readWrite trên elearning database - Authentication Method: Password 2. User Roles Configuration\nBuilt-in Roles: - readWrite: Read và write access - dbAdmin: Database administration - userAdmin: User management - clusterAdmin: Cluster management (admin only) Custom Roles: - course_manager: Course management only - analytics_user: Read-only access - backup_user: Backup operations Database Creation 1. Create Application Database\n// Connect to MongoDB Atlas mongosh \u0026#34;mongodb+srv://elearning_user:password@cluster0.abc123.mongodb.net/\u0026#34; // Create application database use elearning // Create initial collections db.createCollection(\u0026#34;users\u0026#34;) db.createCollection(\u0026#34;courses\u0026#34;) db.createCollection(\u0026#34;enrollments\u0026#34;) db.createCollection(\u0026#34;lessons\u0026#34;) Step 6: Configure Backup \u0026amp; Monitoring Backup Configuration 1. Backup Settings\nBackup Configuration: - Enable: Yes - Frequency: Daily - Retention: 7 days (free tier) / 30 days (paid) - Point-in-time recovery: Enabled - Cloud Provider: Same as cluster 2. Backup Schedule\nBackup Schedule: - Time: [Select low-traffic time] - Frequency: Daily - Retention Policy: 7 days - Point-in-time Recovery: Enabled - Cloud Provider Snapshots: Enabled Monitoring Configuration 1. Performance Advisor\nPerformance Advisor: - Enable: Yes - Monitoring: Slow queries - Index suggestions: Enabled - Schema recommendations: Enabled - Performance insights: Enabled 2. Real-time Performance Panel\nPerformance Metrics: - Operations per second - Query performance - Connection count - Memory usage - Storage usage - Network I/O Step 7: Configure Alerts Alert Configuration 1. Create Basic Alerts\nCPU Usage Alert: - Metric: CPU Usage - Threshold: 80% - Duration: 5 minutes - Action: Email notification Memory Usage Alert: - Metric: Memory Usage - Threshold: 85% - Duration: 5 minutes - Action: Slack notification Connection Count Alert: - Metric: Connection Count - Threshold: 90% of max connections - Duration: 2 minutes - Action: PagerDuty alert 2. Alert Channels\nNotification Methods: - Email: [Your email address] - Slack: [Slack webhook URL] - PagerDuty: [PagerDuty integration] - Webhook: [Custom webhook URL] - SMS: [Phone number] Step 8: Test Connection Connection String 1. Get Connection String\nConnection Information: - Username: elearning_user - Password: [Your password] - Cluster: elearning-cluster-[env] - Database: elearning - Connection String: mongodb+srv://username:password@cluster.mongodb.net/ 2. Test Connection\n# Test with MongoDB Compass # Test with mongosh CLI mongosh \u0026#34;mongodb+srv://elearning_user:password@cluster0.abc123.mongodb.net/elearning\u0026#34; # Test with Spring Boot application # Verify connection in application logs Terminal Screenshot: Chụp màn hình test connection thành công\nApplication Screenshot: Chụp màn hình Spring Boot logs kết nối thành công\nStep 9: Security Hardening Security Settings 1. Security Configuration\nSecurity Features: - TLS/SSL: Enabled (required) - Authentication: Username/password - Network Access: IP whitelist - Database Access: Role-based - Audit Logging: Enabled 2. Advanced Security\nAdvanced Security: - Private Endpoint: [Configure if needed] - Encryption: At rest và in transit - Compliance: SOC2, GDPR, HIPAA - Data Residency: [Select region] - Backup Encryption: Enabled Step 10: Cost Optimization Resource Optimization 1. Cluster Sizing\nRight-sizing Strategy: - Start with smaller instances - Monitor resource usage - Scale up based on demand - Use auto-scaling when available - Regular performance review 2. Cost Monitoring\nCost Management: - Enable billing alerts - Monitor usage patterns - Review monthly costs - Optimize storage usage - Use reserved instances (if available) Troubleshooting Common Issues Connection Problems\n# Check IP whitelist # Verify username/password # Check network connectivity # Verify cluster status # Test with mongosh mongosh \u0026#34;mongodb+srv://username:password@cluster.mongodb.net/\u0026#34; Performance Issues\n// Check slow queries db.getProfilingStatus() db.setProfilingLevel(1, 100) // Check index usage db.users.getIndexes() db.courses.getIndexes() // Analyze query performance db.users.find({email: \u0026#34;user@example.com\u0026#34;}).explain(\u0026#34;executionStats\u0026#34;) Next Steps Với MongoDB Atlas cluster đã được thiết lập, chúng ta có thể:\nCấu hình Spring Boot integration Implement data models và repositories Thiết lập advanced monitoring Configure backup và recovery procedures Key Takeaways MongoDB Atlas setup yêu cầu careful planning cho production use Network access phải được cấu hình đúng để cho phép application access Database users và roles cần được thiết lập với minimal privileges Monitoring và alerting cần thiết cho production environments Backup configuration quan trọng cho data protection Security hardening cần được implement từ đầu "
},
{
	"uri": "//localhost:1313/2-rds-mysql-springboot/2.1-rds-instance-setup/",
	"title": "RDS Instance Setup",
	"tags": [],
	"description": "",
	"content": "RDS Instance Setup Overview Trong phần này, chúng ta sẽ thiết lập Amazon RDS instance với MySQL từ đầu. Bạn sẽ học cách tạo RDS instance, cấu hình security groups, và thiết lập các thông số cần thiết cho ứng dụng e-learning platform.\nPrerequisites AWS Account Setup Required Services\nAWS Account: Active AWS account với billing enabled IAM Permissions: Quyền tạo và quản lý RDS resources VPC Setup: Virtual Private Cloud với public và private subnets Security Groups: Network security configuration IAM Permissions Required\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;rds:*\u0026#34;, \u0026#34;ec2:DescribeVpcs\u0026#34;, \u0026#34;ec2:DescribeSubnets\u0026#34;, \u0026#34;ec2:DescribeSecurityGroups\u0026#34;, \u0026#34;kms:ListKeys\u0026#34;, \u0026#34;kms:DescribeKey\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Step 1: Create RDS Instance AWS Console Setup 1. Navigate to RDS Service\n# Mở AWS Console # Tìm kiếm \u0026#34;RDS\u0026#34; service # Click \u0026#34;Create database\u0026#34; 2. Choose Database Creation Method\nStandard create: Full control over configuration Easy create: AWS recommended settings Select \u0026ldquo;Standard create\u0026rdquo; for custom configuration 3. Engine Options\nEngine type: MySQL Version: MySQL 8.0.28 (Recommended) Templates: Production (Multi-AZ) Instance Configuration Basic Settings\nDB instance identifier: [tên ] Master username: admin Master password: [Strong password with 8+ characters] Confirm password: [Same password] Instance Configuration\nDB instance class: db.t3.micro (Free tier) / db.m5.large (Production) Instance type: Burstable classes (includes previous generation) Storage type: General Purpose SSD (gp2) Allocated storage: 20 GB Storage autoscaling: Enable Maximum storage threshold: 1000 GB Step 2: Network Configuration VPC and Subnet Configuration Security Group Configuration Create Security Group\nSecurity group name: cái mà mình vừa tạo Description: Security group for e-learning database Inbound Rules\nType: MySQL/Aurora Protocol: TCP Port: 3306 Source: [Your application security group] / [Specific IP ranges] Description: MySQL access from application Step 3: Database Configuration Additional Configuration Database Options\nDatabase name: [Default] Database port: 3306 DB parameter group: [Default] Option group: [Default] hostname:[your-endpoints] password:[password you set] hãy test connection nếu thành công thì rds của bạn đã được tạo và kết nối với dblocal Hãy chạy và test thử Step 8: Monitoring Setup CloudWatch Alarms Create Basic Alarms\nCPU Utilization Alarm: - Metric: CPUUtilization - Threshold: 80% - Period: 5 minutes - Actions: Send notification Free Storage Space Alarm: - Metric: FreeStorageSpace - Threshold: 2 GB - Period: 5 minutes - Actions: Send notification Database Connections Alarm: - Metric: DatabaseConnections - Threshold: 80% of max_connections - Period: 5 minutes - Actions: Send notification Dashboard Creation Create RDS Dashboard\nDashboard name: E-Learning Database Dashboard Widgets: - CPU Utilization - Memory Usage - Storage Space - Active Connections - Read/Write IOPS - Network Throughput Troubleshooting Common Issues Connection Problems\n# Check security group rules aws ec2 describe-security-groups --group-ids [sg-xxxxx] # Verify VPC configuration aws ec2 describe-vpcs --vpc-ids [vpc-xxxxx] # Test network connectivity telnet [RDS_ENDPOINT] 3306 Performance Issues\n-- Check slow queries SHOW VARIABLES LIKE \u0026#39;slow_query_log\u0026#39;; SHOW VARIABLES LIKE \u0026#39;long_query_time\u0026#39;; -- Analyze table statistics ANALYZE TABLE [table_name]; -- Check index usage SHOW INDEX FROM [table_name]; Next Steps Với RDS instance đã được thiết lập, chúng ta có thể:\nCấu hình Spring Boot application để kết nối Thiết lập database migration strategies Implement monitoring và alerting Tối ưu hóa performance Key Takeaways RDS instance setup yêu cầu careful planning cho production use Security groups phải được cấu hình đúng để cho phép application access Parameter groups cho phép tối ưu hóa database performance Monitoring và alerting cần thiết cho production environments SSL/TLS nên được enable cho secure connections Backup và maintenance windows cần được cấu hình phù hợp "
},
{
	"uri": "//localhost:1313/3-amazon-s3-storage/3.1-s3-bucket-setup/",
	"title": "S3 Bucket Setup &amp; Configuration",
	"tags": [],
	"description": "",
	"content": "S3 Bucket Setup \u0026amp; Configuration Overview Trong phần này, chúng ta sẽ thiết lập Amazon S3 buckets từ đầu, cấu hình security, và thiết lập các tính năng cần thiết cho e-learning platform. Bạn sẽ học cách tạo buckets, cấu hình access policies, và thiết lập lifecycle management.\nPrerequisites AWS Account Setup Required Services\nAWS Account: Active AWS account với billing enabled IAM Permissions: Quyền tạo và quản lý S3 resources VPC Setup: Virtual Private Cloud (nếu sử dụng VPC endpoints) IAM Users/Roles: Để cấu hình access policies IAM Permissions Required\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:*\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:PassRole\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Step 1: Create S3 Buckets Create Main Content Bucket 1. Navigate to S3 Service\n# Mở AWS Console # Tìm kiếm \u0026#34;S3\u0026#34; service # Click \u0026#34;Create bucket\u0026#34; 2. Basic Bucket Configuration\nBucket name: elearning-content-[region]-[env] - Example: elearning-content-us-east-1-prod - Must be globally unique - Use lowercase letters, numbers, hyphens - Avoid underscores and periods AWS Region: [Select your preferred region] - Consider latency to your application - Consider compliance requirements - Consider cost differences **Public Access Settings** ```yaml Block all public access: Enabled - Block public access through bucket policies - Block public access through ACLs - Block public access through any access control lists - Block public access through bucket policies Override settings: Disabled - Maintain consistent security across account - Prevent accidental public access - Follow security best practices Step 2: Configure Bucket Settings Object Ownership ACLs Configuration\nACLs: Disabled (Recommended) - Prevents accidental public access - Better security control - Use bucket policies instead Object Ownership: Bucket owner enforced - Simplifies access control - Prevents ACL conflicts - Better security management Step 3: Tạo user IAM cho S3 Vào IAM → Users → Add users. Nhập tên: elearning-s3-user. Chọn Access key - Programmatic access (để Spring Boot dùng). Attach policy: chọn AmazonS3FullAccess hoặc custom chỉ cho 1 bucket. Tạo xong, lưu lại Access Key ID và Secret Access Key (chỉ hiển thị 1 lần). Benefits: - Centralized key management - Detailed access logging - Integration with IAM policies - Compliance requirements Bước 1 — Đặt tên \u0026amp; quyền truy cập Bạn đã đặt tên elearning-s3-user → OK. Không cần tick \u0026#34;Provide user access to the AWS Management Console\u0026#34; vì bạn chỉ cần programmatic access (dùng Access Key cho code). Nhấn Next. Bước 2 — Set permissions Chọn Attach policies directly. Tìm AmazonS3FullAccess (nếu muốn dễ test ban đầu) hoặc tạo Custom Policy giới hạn trong 1 bucket cho bảo mật. Tick chọn policy → Next. Bước 3 — Tạo user \u0026amp; lưu Access Key Review thông tin → Create user. AWS sẽ hiển thị Access key ID và Secret access key → lưu ngay, vì Secret Key chỉ hiện một lần. Sau này bạn dùng thông tin này để cấu hình trong application.properties Spring Boot. Thành công tạo user IAM tạo Access Key: Vào AWS Console → Tìm dịch vụ IAM (Identity and Access Management). Trong Users, chọn user bạn đang dùng (hoặc tạo user mới với quyền S3). Chọn tab Security credentials → Create access key. AWS sẽ cho bạn Access Key ID và Secret Access Key → tải file .csv hoặc copy lại ngay (vì Secret chỉ hiện một lần). Lưu cặp key này vào AWS CLI, hoặc trong file .env / biến môi trường để Spring Boot đọc. ⚠ Lưu ý bảo mật: Không commit Access Key vào GitHub. Step 5: Configure Access Control Bucket Policies Access Control Policies\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::elearning-uploads-ap-southeast-1/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontServicePrincipal\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::elearning-uploads-ap-southeast-1/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;ArnLike\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: [ \u0026#34;arn:aws:cloudfront::470840853649:distribution/E2TAEJ7I6RYQ78\u0026#34;, \u0026#34;arn:aws:cloudfront::470840853649:distribution/E3QCNLF25XUK0R\u0026#34; ] } } } ] } IAM Policies User and Role Access\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::elearning-content-*\u0026#34;, \u0026#34;arn:aws:s3:::elearning-content-*/*\u0026#34; ], \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:PrincipalTag/Role\u0026#34;: \u0026#34;E-Learning-User\u0026#34; } } } ] } Step 6: Configure CORS Cross-Origin Resource Sharing CORS Configuration\n[ { \u0026#34;AllowedHeaders\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;AllowedMethods\u0026#34;: [ \u0026#34;GET\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;POST\u0026#34; ], \u0026#34;AllowedOrigins\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;ExposeHeaders\u0026#34;: [ \u0026#34;ETag\u0026#34; ] } ] CORS Use Cases Common Scenarios\nWeb Application: - Allow uploads from web interface - Enable direct browser access - Support drag-and-drop functionality - Handle preflight requests Mobile Application: - Allow mobile app access - Support offline sync - Handle authentication tokens - Manage session cookies Next Steps Với S3 buckets đã được thiết lập, chúng ta có thể:\nCấu hình Spring Boot integration Implement file upload/download services Thiết lập CloudFront CDN Configure advanced monitoring và analytics Key Takeaways S3 bucket setup yêu cầu careful planning cho security và cost Access control phải được cấu hình đúng để bảo vệ data Lifecycle policies giúp tối ưu hóa chi phí storage Monitoring và analytics cần thiết cho production environments CORS configuration cần thiết cho web application access Cost optimization cần được monitor và adjust regularly "
},
{
	"uri": "//localhost:1313/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Esoclusty E-Learning Platform Workshop Overview Chào mừng bạn đến với workshop về Esoclusty E-Learning Platform! Đây là một nền tảng học tập trực tuyến toàn diện được xây dựng với Spring Boot, tích hợp cả MySQL và MongoDB để cung cấp trải nghiệm học tập tốt nhất.\nPlatform Features Multi-Role User Management: Hệ thống quản lý người dùng với 3 vai trò (Admin, Teacher, Student) Comprehensive Course Management: Quản lý khóa học toàn diện với nội dung đa phương tiện Real-time Communication: Tính năng giao tiếp thời gian thực với WebSocket Advanced Assessment System: Hệ thống đánh giá và theo dõi tiến độ học tập Hybrid Database Architecture: Kiến trúc cơ sở dữ liệu kết hợp MySQL và MongoDB Automated Migration System: Hệ thống tự động hóa database migration Technology Stack Backend: Spring Boot 3.4.5, Java 17, Spring Framework 6 Databases: MySQL 8.0+, MongoDB 4.4+ Security: Spring Security 6 với JWT authentication Real-time: WebSocket với STOMP protocol Frontend: Thymeleaf templates Build Tool: Maven 3.9+ Cloud Services: AWS RDS, S3, MongoDB Atlas Workshop Structure 1. Technology Overview Tìm hiểu về công nghệ và kiến trúc của platform:\nBackend Framework: Spring Boot, Java, Spring Framework Database Technologies: MySQL, MongoDB, hybrid strategy Third-Party Dependencies: Security, content processing, monitoring Explore Technology Overview →\n2. RDS với MySQL - Spring Boot Integration Thiết lập Amazon RDS với MySQL và tích hợp Spring Boot:\nRDS Instance Setup: Tạo và cấu hình RDS instance Spring Boot Configuration: Cấu hình kết nối database Database Migration: Quản lý schema và migration Explore RDS MySQL Integration →\n3. Amazon S3 - File Storage \u0026amp; Management Thiết lập Amazon S3 cho file storage:\nS3 Bucket Setup: Tạo và cấu hình S3 buckets Spring Boot Integration: Tích hợp S3 với ứng dụng Advanced Features: CloudFront, monitoring, cost optimization Explore S3 Storage →\n4. MongoDB Atlas - Cloud Database Service Thiết lập MongoDB Atlas cho document storage:\nAtlas Setup: Tạo cluster và cấu hình Spring Boot Integration: Tích hợp MongoDB với ứng dụng Advanced Features: Search, analytics, global clusters Explore MongoDB Atlas →\nPrerequisites Trước khi bắt đầu workshop, bạn cần:\nJava Development Kit: JDK 17 hoặc cao hơn Maven: Version 3.9+ để quản lý dependencies IDE: IntelliJ IDEA, Eclipse, hoặc VS Code AWS Account: Để sử dụng RDS và S3 services MongoDB Atlas Account: Để sử dụng cloud database service Git: Để clone repository và quản lý code Expected Outcomes Sau khi hoàn thành workshop, bạn sẽ có thể:\nThiết lập và cấu hình RDS MySQL instance trên AWS Tạo và quản lý S3 buckets cho file storage Thiết lập MongoDB Atlas cluster cho document storage Tích hợp tất cả services với Spring Boot application Hiểu rõ kiến trúc hybrid database của platform Thực hiện database migration một cách an toàn Tối ưu hóa performance và cost cho production Getting Started Clone Repository: git clone https://github.com/huyIT203/e-learning.git Navigate to Backend: cd e-learning/elearning-backend Review Documentation: Đọc README.md và docs/vi/ Follow Workshop Sections: Bắt đầu với Technology Overview Practice Hands-on: Thực hành từng bước theo hướng dẫn Support and Resources GitHub Repository: https://github.com/huyIT203/e-learning Documentation: Xem thư mục docs/vi/ cho tài liệu tiếng Việt Issues: Báo cáo vấn đề trên GitHub Issues Discussions: Tham gia thảo luận trên GitHub Discussions Next Steps Bắt đầu workshop bằng cách khám phá Technology Overview để hiểu rõ về kiến trúc và công nghệ của platform. Sau đó, tiếp tục với các phần thiết lập cloud services để xây dựng môi trường production-ready.\nChúc bạn có một trải nghiệm học tập tuyệt vời với Esoclusty E-Learning Platform!\n"
},
{
	"uri": "//localhost:1313/1-create-new-aws-account/",
	"title": "Creating a new AWS Account",
	"tags": [],
	"description": "",
	"content": "Content:\nCreate an AWS account Add payment method Verify your phone number Select Support Plan Wait for your account to be activated Important Warning Create an AWS account Go to the Amazon Web Service homepage page. Select Create an AWS Account in the upper right corner. Note: If you don\u0026rsquo;t see Create an AWS Account, select Sign In to the Console then select Create a new AWS Account. Enter email information and AWS account name Complete information. Confirm the code sent from the email. After successful email authentication. You complete the account information. Complete the account registration documents. You can choose Personal or Business account Add payment method Enter your credit card information and select Verify and Add. Note: You can choose a different address for your account by selecting Use a new address before Verify and Add. Verify your phone number Enter the phone number. Enter the security check code then select Call me now. AWS will contact and verify account opening. Select Support Plan In the Select a support plan page, select an effective plan, to compare plans, see Compare AWS Support Plans. Wait for your account to be activated After selecting Support plan, the account is usually activated after a few minutes, but the process can take up to 24 hours. You will still be able to log in to your AWS account at this time, the AWS Home page may show a “Complete Sign Up” button during this time, even if you have completed all the steps in the registration section. After receiving an email confirming your account has been activated, you can access all AWS services. Important The following AWS Identity and Access Management (IAM) actions will reach the end of standard support on July 2023: aws-portal:ModifyAccount and aws-portal:ViewAccount. See the Using fine-grained AWS Billing actions to replace these actions with fine-grained actions so you have access to AWS Billing, AWS Cost Management, and AWS accounts consoles.\nIf you created your AWS account or AWS Organizations Management account before March 6, 2023, the fine-grained actions will be effective starting July 2023. We recommend you to add the fine-grained actions, but not remove your existing permissions with aws-portal or purchase-orders prefixes.\nIf you created your AWS account or AWS Organizations Management account on or after March 6, 2023, the fine-grained actions are effective immediately.\nAWS assigns the following unique identifiers to each AWS account:\nAWS account ID: A 12-digit number, such as 012345678901, that uniquely identifies an AWS account. Many AWS resources include the account ID in their Amazon Resource Names (ARNs). The account ID portion distinguishes resources in one account from the resources in another account. If you\u0026rsquo;re an AWS Identity and Access Management (IAM) user, you can sign in to the AWS Management Console using either the account ID or account alias. While account IDs, like any identifying information, should be used and shared carefully, they are not considered secret, sensitive, or confidential information.\nCanonical user ID: An alpha-numeric identifier, such as 79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be, that is an obfuscated form of the AWS account ID. You can use this ID to identify an AWS account when granting cross-account access to buckets and objects using Amazon Simple Storage Service (Amazon S3). You can retrieve the canonical user ID for your AWS account as either the root user or an IAM user.\nYou must be authenticated with AWS to view these identifiers.\nWarning Do not provide your AWS credentials (including passwords and access keys) to a third party that needs your AWS account identifiers to share AWS resources with you. Doing so would give them the same access to the AWS account that you have.\n"
},
{
	"uri": "//localhost:1313/1-create-new-aws-account/1.1-find-account-id/",
	"title": "Finding Account ID",
	"tags": [],
	"description": "",
	"content": "View AWS account identifiers Finding your account ID as the root user You can find the AWS account ID using either the AWS Management Console or the AWS Command Line Interface (AWS CLI). In the console, the location of the account ID depends on whether you\u0026rsquo;re signed in as the root user or an IAM user. The account ID remains the same whether you\u0026rsquo;re signed in as the root user or an IAM user.\nMinimum Permissions To perform the following steps, you must have at least the following IAM permissions:\nWhen you sign in as the root user, you don\u0026rsquo;t need any IAM permissions. In the navigation bar on the upper right, choose your account name or number and then choose Security credentials. Tip: If you don\u0026rsquo;t see the Security credentials option, you might be signed in as a federated user with an IAM role, instead of as an IAM user. In this case, look for the entry Account and the account ID number next to it.\nUnder the Account details section, the account number appears next to AWS account ID.\nFinding Your AWS Account ID as an IAM User Minimum Permissions To perform the following steps, you must have at least the following IAM permission:\naws-portal:ViewAccount In the navigation bar on the upper right, choose your user name and then choose Security credentials.\nTip: If you don\u0026rsquo;t see the Security credentials option, you might be signed in as a federated user with an IAM role, instead of as an IAM user. In this case, look for the entry Account and the account ID number next to it.\nAt the top of the page, under Account details, the account number appears next to AWS account ID.\nFind the canonical user ID for your AWS account You can find the canonical user ID for your AWS account using the AWS Management Console or the AWS CLI. The canonical user ID for an AWS account is specific to that account. You can retrieve the canonical user ID for your AWS account as the root user, a federated user, or an IAM user.\nFind the canonical ID as the root user or IAM user To find the canonical user ID for your account when signed in to the console as the root user or an IAM user:\nMinimum permissions:\nTo perform the following steps, you must have at least the following IAM permissions:\nWhen you run the command as the root user, you don\u0026rsquo;t need any IAM permissions. When you sign in as an IAM user, then you must have: aws-portal:ViewAccount Sign in to the AWS Management Console as the root user or an IAM user.\nIn the navigation bar on the upper right, choose your account name or number, and then choose \u0026ldquo;Security credentials\u0026rdquo;.\nTip: If you don\u0026rsquo;t see the \u0026ldquo;Security credentials\u0026rdquo; option, you might be signed in as a federated user with an IAM role, instead of as an IAM user. In this case, look for the entry \u0026ldquo;Account\u0026rdquo; and the account ID number next to it.\nUnder the \u0026ldquo;Account details\u0026rdquo; section, the canonical user ID appears next to \u0026ldquo;Canonical user ID\u0026rdquo;. You can use your canonical user ID to configure Amazon S3 access control lists (ACLs).\nFind the canonical ID as a federated user with an IAM role To find the canonical ID for your account when signed in to the console as a federated user with an IAM role\nMinimum Permissions You must have permission to list and view an Amazon S3 bucket.\nSign in to the AWS Management Console as a federated user with an IAM role. In the Amazon S3 console, choose a bucket name to view details about a bucket. Choose the Permissions tab. In the Access control list section, under Bucket owner, the canonical ID for your AWS account appears. "
},
{
	"uri": "//localhost:1313/2-rds-mysql-springboot/",
	"title": "RDS với MySQL - Spring Boot Integration",
	"tags": [],
	"description": "",
	"content": "RDS với MySQL - Spring Boot Integration Overview Trong phần này, chúng ta sẽ thiết lập và cấu hình Amazon RDS với MySQL để tích hợp với ứng dụng Spring Boot. Bạn sẽ học cách tạo RDS instance, cấu hình kết nối, và tích hợp với ứng dụng e-learning platform. Đặc biệt, chúng ta sẽ sử dụng Flyway để quản lý database migration một cách tự động và an toàn.\nSection Contents 2.1 RDS Instance Setup Thiết lập Amazon RDS instance với MySQL:\nRDS Instance Creation: Tạo và cấu hình RDS instance Security Group Configuration: Cấu hình bảo mật và network access Database Configuration: Thiết lập database parameters và options Backup and Maintenance: Cấu hình backup và maintenance windows Monitoring and Alerts: Thiết lập CloudWatch monitoring Explore RDS Instance Setup →\n2.2 Spring Boot Database Configuration Cấu hình Spring Boot để kết nối với RDS:\nDatabase Connection: Cấu hình kết nối database với RDS Flyway Integration: Thiết lập Flyway cho database migration JPA Configuration: Cấu hình Hibernate và JPA Connection Pooling: Tối ưu hóa Hikari connection pool Environment Configuration: Quản lý cấu hình cho các môi trường khác nhau Explore Spring Boot Configuration →\n2.3 Database Migration with Flyway Quản lý schema và migration với Flyway:\nFlyway Setup: Cấu hình Flyway trong Spring Boot Migration Scripts: Tạo và quản lý SQL migration scripts Schema Versioning: Quản lý version của database schema Rollback Procedures: Quy trình rollback khi cần thiết Testing Strategies: Chiến lược testing cho database changes Explore Database Migration →\nRDS Overview Amazon RDS Benefits Managed Database Service\nAutomated Management: AWS tự động quản lý database administration High Availability: Multi-AZ deployment cho high availability Scalability: Easy scaling up/down theo nhu cầu Security: Built-in security features và encryption Backup: Automated backup và point-in-time recovery MySQL on RDS\nVersion Support: Hỗ trợ MySQL 5.7, 8.0, và các version mới nhất Performance: Optimized cho performance và reliability Compatibility: Tương thích 100% với MySQL community edition Monitoring: Detailed monitoring và performance insights RDS Instance Types Instance Class Selection General Purpose (M5, M6g)\nUse Case: Development, testing, và small production workloads Memory: 2-384 GB RAM vCPU: 2-128 vCPUs Storage: Up to 64 TB Network: Up to 25 Gbps Memory Optimized (R5, R6g)\nUse Case: High-performance database workloads Memory: 16-768 GB RAM vCPU: 2-96 vCPUs Storage: Up to 64 TB Network: Up to 25 Gbps Burstable Performance (T3)\nUse Case: Development và light production workloads Memory: 0.5-16 GB RAM vCPU: 2-8 vCPUs Storage: Up to 16 TB Network: Up to 5 Gbps Storage Options Storage Types General Purpose SSD (gp2)\nPerformance: 3 IOPS per GB, up to 16,000 IOPS Use Case: Most workloads Cost: Most cost-effective Size: 20 GB to 64 TB Provisioned IOPS SSD (io1)\nPerformance: Up to 64,000 IOPS Use Case: High-performance workloads Cost: Higher cost for high IOPS Size: 100 GB to 64 TB Magnetic Storage\nPerformance: 100-200 IOPS Use Case: Legacy applications Cost: Lowest cost Size: 20 GB to 1 TB Security Features Network Security VPC Configuration\nPrivate Subnets: RDS instance trong private subnets Security Groups: Restrict access to specific IP ranges Network ACLs: Additional network layer security VPC Endpoints: Private connection to AWS services Encryption\nEncryption at Rest: AES-256 encryption cho data storage Encryption in Transit: SSL/TLS encryption cho connections Key Management: AWS KMS integration Certificate Management: Automated certificate rotation Monitoring and Maintenance CloudWatch Integration Metrics Available\nDatabase Metrics: CPU, memory, storage, connections Network Metrics: Network throughput và latency Storage Metrics: IOPS, storage space, read/write operations Custom Metrics: Application-specific metrics Alarms and Notifications\nCPU Utilization: Alert khi CPU usage cao Memory Usage: Monitor memory consumption Storage Space: Alert khi storage gần đầy Connection Count: Monitor active connections Maintenance Windows Automated Maintenance\nSecurity Updates: Automated security patches Engine Updates: Minor version updates System Updates: OS và infrastructure updates Scheduling: Configurable maintenance windows Cost Optimization Pricing Factors Instance Pricing\nOn-Demand: Pay per hour, no commitment Reserved Instances: 1-3 year commitment, significant savings Spot Instances: Not available for RDS Multi-AZ: Additional cost for high availability Storage Pricing\nProvisioned Storage: Pay for allocated storage IOPS: Additional cost for provisioned IOPS Backup Storage: Free storage up to 100% of database size Data Transfer: Charges for data transfer out of AWS Flyway Integration Benefits Database Migration Management Automated Schema Management\nVersion Control: Mỗi thay đổi database được version control Repeatable: Migration scripts có thể chạy lại trên môi trường khác Rollback Support: Hỗ trợ rollback về version trước Team Collaboration: Multiple developers có thể làm việc cùng lúc Production Benefits\nZero Downtime: Migration có thể thực hiện với minimal downtime Audit Trail: Lịch sử thay đổi database được ghi lại đầy đủ Environment Consistency: Đảm bảo tất cả môi trường có cùng schema Automated Deployment: Tích hợp với CI/CD pipeline Next Steps Trong các phần tiếp theo, chúng ta sẽ:\nThiết lập RDS instance cụ thể với cấu hình thực tế Cấu hình Spring Boot application với Flyway integration Implement database migration strategies Thiết lập monitoring và alerting Key Takeaways Amazon RDS cung cấp managed MySQL service với high availability Multiple instance types phù hợp với các workload khác nhau Built-in security với encryption và network isolation Automated management giảm thiểu administrative overhead Flyway integration cung cấp database migration automation Cost optimization với reserved instances và storage optimization "
},
{
	"uri": "//localhost:1313/2-rds-mysql-springboot/2.2-springboot-configuration/",
	"title": "Spring Boot Database Configuration",
	"tags": [],
	"description": "",
	"content": "Spring Boot Database Configuration Overview Trong phần này, chúng ta sẽ cấu hình Spring Boot application để kết nối với Amazon RDS MySQL instance. Bạn sẽ học cách thiết lập database connection, cấu hình Flyway cho migration, và tối ưu hóa connection pooling với Hikari.\nPrerequisites Project Setup Required Dependencies\nSpring Boot 3.4.5: Core framework Spring Data JPA: Database access layer MySQL Driver: MySQL connector for Java Flyway: Database migration tool HikariCP: Connection pooling Maven Dependencies\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.33\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.flywaydb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flyway-core\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.flywaydb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flyway-mysql\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Step 1: Database Connection Configuration Application Properties Database Configuration\n# Database Configuration - RDS MySQL spring.datasource.url=jdbc:mysql://[RDS_ENDPOINT]:3306/elearning?createDatabaseIfNotExist=true\u0026amp;useSSL=false\u0026amp;allowPublicKeyRetrieval=true spring.datasource.username=[YOUR_USERNAME] spring.datasource.password=[YOUR_PASSWORD] spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver # JPA Configuration spring.jpa.hibernate.ddl-auto=update spring.jpa.show-sql=true spring.jpa.properties.hibernate.format_sql=true spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQLDialect Connection Parameters Explanation\ncreateDatabaseIfNotExist=true: - Tự động tạo database nếu chưa tồn tại - Hữu ích cho development environment - Không nên dùng trong production useSSL=false: - Tắt SSL connection cho development - Production nên enable SSL - Cần cấu hình SSL certificates allowPublicKeyRetrieval=true: - Cho phép MySQL server gửi public key - Cần thiết cho MySQL 8.0+ - Security consideration Step 2: Flyway Configuration Flyway Setup Flyway Configuration Properties\n# Flyway Configuration spring.flyway.enabled=true spring.flyway.baseline-on-migrate=true spring.flyway.baseline-version=0 spring.flyway.baseline-description=Initial baseline spring.flyway.locations=classpath:db/migration spring.flyway.table=flyway_schema_history spring.flyway.validate-on-migrate=false spring.flyway.clean-disabled=true spring.flyway.out-of-order=true spring.flyway.mixed=true Migration Scripts Structure File Naming Convention\nMigration Script Format: - V1__Create_users_table.sql - V2__Add_email_index.sql - V3__Create_courses_table.sql - V4__Add_enrollment_relationship.sql Version Numbering: - V1, V2, V3... (Sequential) - V1.1, V1.2... (Minor versions) - V20240101__Initial_schema.sql (Date-based) Step 3: Connection Pooling Configuration Hikari Connection Pool Hikari Configuration\n# Hikari Connection Pool spring.datasource.hikari.connection-timeout=20000 spring.datasource.hikari.maximum-pool-size=10 spring.datasource.hikari.minimum-idle=5 spring.datasource.hikari.idle-timeout=300000 spring.datasource.hikari.max-lifetime=1200000 spring.datasource.hikari.leak-detection-threshold=60000 # Additional JPA Settings spring.jpa.properties.hibernate.jdbc.time_zone=UTC spring.jpa.open-in-view=false Step 4: JPA and Hibernate Configuration Entity Configuration JPA Entity Example\n@Entity @Table(name = \u0026#34;users\u0026#34;) public class User { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(nullable = false, unique = true) private String email; @Column(name = \u0026#34;first_name\u0026#34;) private String firstName; @Column(name = \u0026#34;last_name\u0026#34;) private String lastName; @Enumerated(EnumType.STRING) private UserRole role; @Column(name = \u0026#34;created_at\u0026#34;) private LocalDateTime createdAt; // Constructors, getters, setters } Next Steps Với Spring Boot configuration đã được thiết lập, chúng ta có thể:\nTạo và quản lý migration scripts với Flyway Implement database entities và repositories Thiết lập testing environment Monitor database performance Key Takeaways Database configuration cần được tối ưu hóa cho từng môi trường Flyway integration cung cấp automated database migration Connection pooling với Hikari tối ưu hóa performance Profile-based configuration cho phép quản lý multiple environments Health checks cần thiết cho production monitoring Testing configuration đảm bảo code quality và reliability "
},
{
	"uri": "//localhost:1313/3-amazon-s3-storage/3.2-springboot-integration/",
	"title": "Spring Boot S3 Integration",
	"tags": [],
	"description": "",
	"content": "Overview Trong phần này, chúng ta sẽ tích hợp Amazon S3 với Spring Boot application để quản lý file upload/download. Bạn sẽ học cách cấu hình AWS SDK, tạo S3Service, và implement FileController để xử lý file operations một cách hiệu quả và an toàn.\nPrerequisites Project Setup Required Dependencies\nSpring Boot 3.4.5: Core framework AWS SDK v2: Modern AWS SDK for Java Spring Web: REST API support Spring Boot Starter: Auto-configuration Maven Dependencies\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.awssdk\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;s3\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Step 1: AWS SDK Configuration S3Config Class Configuration Setup\npackage com.elearning.elearning_backend.Config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import software.amazon.awssdk.auth.credentials.AwsBasicCredentials; import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider; import software.amazon.awssdk.regions.Region; import software.amazon.awssdk.services.s3.S3Client; @Configuration public class S3config { @Bean public S3Client s3Client() { return S3Client.builder() .region(Region.AP_SOUTHEAST_1) .credentialsProvider(StaticCredentialsProvider.create( AwsBasicCredentials.create(\u0026#34;[YOUR_ACCESS_KEY]\u0026#34;, \u0026#34;[YOUR_SECRET_KEY]\u0026#34;) )) .build(); } } Environment Variables (Recommended)\n# AWS Configuration aws.access.key.id=[YOUR_ACCESS_KEY] aws.secret.access.key=[YOUR_SECRET_KEY] aws.region=ap-southeast-1 aws.s3.bucket.name=elearning-uploads-ap-southeast-1 Step 2: S3Service Implementation Service Interface S3Service Interface\npackage com.elearning.elearning_backend.Service; import org.springframework.web.multipart.MultipartFile; import java.io.IOException; public interface S3Service { String uploadFile(MultipartFile file) throws IOException; byte[] downloadFile(String fileName) throws IOException; void deleteFile(String fileName); String getFileUrl(String fileName); } Service Implementation S3Service Implementation\npackage com.elearning.elearning_backend.Service; import org.springframework.stereotype.Service; import org.springframework.web.multipart.MultipartFile; import software.amazon.awssdk.services.s3.S3Client; import software.amazon.awssdk.services.s3.model.PutObjectRequest; import software.amazon.awssdk.services.s3.model.GetObjectRequest; import software.amazon.awssdk.services.s3.model.DeleteObjectRequest; import software.amazon.awssdk.core.sync.RequestBody; import java.io.IOException; @Service public class S3Service { private final S3Client s3Client; private final String bucketName = \u0026#34;elearning-uploads-ap-southeast-1\u0026#34;; public S3Service(S3Client s3Client) { this.s3Client = s3Client; } public String uploadFile(MultipartFile file) throws IOException { String keyName = file.getOriginalFilename(); String contentType = file.getContentType(); s3Client.putObject(PutObjectRequest.builder() .bucket(bucketName) .key(keyName) .contentType(contentType) .build(), RequestBody.fromBytes(file.getBytes()) ); return \u0026#34;https://\u0026#34; + bucketName + \u0026#34;.s3.amazonaws.com/\u0026#34; + keyName; } public byte[] downloadFile(String fileName) throws IOException { var objectResponse = s3Client.getObject(GetObjectRequest.builder() .bucket(bucketName) .key(fileName) .build()); return objectResponse.readAllBytes(); } public void deleteFile(String fileName) { s3Client.deleteObject(DeleteObjectRequest.builder() .bucket(bucketName) .key(fileName) .build()); } public String getFileUrl(String fileName) { return \u0026#34;https://\u0026#34; + bucketName + \u0026#34;.s3.amazonaws.com/\u0026#34; + fileName; } } Step 3: FileController Implementation REST API Endpoints FileController Class\npackage com.elearning.elearning_backend.Controller; import com.elearning.elearning_backend.Service.S3Service; import org.springframework.http.HttpHeaders; import org.springframework.http.MediaType; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.*; import org.springframework.web.multipart.MultipartFile; import java.io.IOException; @RestController @RequestMapping(\u0026#34;/files\u0026#34;) public class FileController { private final S3Service s3Service; public FileController(S3Service s3Service) { this.s3Service = s3Service; } @PostMapping(\u0026#34;/upload\u0026#34;) public String uploadFile(@RequestParam(\u0026#34;file\u0026#34;) MultipartFile file) throws Exception { return s3Service.uploadFile(file); } @GetMapping(\u0026#34;/download/{fileName}\u0026#34;) public ResponseEntity\u0026lt;byte[]\u0026gt; downloadFile(@PathVariable String fileName) throws IOException { byte[] fileData = s3Service.downloadFile(fileName); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); headers.setContentDispositionFormData(\u0026#34;attachment\u0026#34;, fileName); return ResponseEntity.ok() .headers(headers) .body(fileData); } @DeleteMapping(\u0026#34;/{fileName}\u0026#34;) public String deleteFile(@PathVariable String fileName) { s3Service.deleteFile(fileName); return \u0026#34;File \u0026#34; + fileName + \u0026#34; deleted successfully\u0026#34;; } @GetMapping(\u0026#34;/url/{fileName}\u0026#34;) public String getFileUrl(@PathVariable String fileName) { return s3Service.getFileUrl(fileName); } } Step 4: File Upload Configuration Multipart Configuration Application Properties\n# File Upload Configuration spring.servlet.multipart.max-file-size=5MB spring.servlet.multipart.max-request-size=5MB spring.servlet.multipart.enabled=true # AWS S3 Configuration cloud.aws.region.static=ap-southeast-1 cloud.aws.s3.bucket-name=elearning-uploads-ap-southeast-1 cloud.aws.credentials.access-key=[YOUR_ACCESS_KEY] cloud.aws.credentials.secret-key=[YOUR_SECRET_KEY] File Size Validation\n@Component public class FileValidationService { private static final long MAX_FILE_SIZE = 5 * 1024 * 1024; // 5MB private static final List\u0026lt;String\u0026gt; ALLOWED_EXTENSIONS = Arrays.asList(\u0026#34;jpg\u0026#34;, \u0026#34;jpeg\u0026#34;, \u0026#34;png\u0026#34;, \u0026#34;gif\u0026#34;, \u0026#34;pdf\u0026#34;, \u0026#34;doc\u0026#34;, \u0026#34;docx\u0026#34;, \u0026#34;txt\u0026#34;); public boolean isValidFile(MultipartFile file) { // Check file size if (file.getSize() \u0026gt; MAX_FILE_SIZE) { return false; } // Check file extension String originalFilename = file.getOriginalFilename(); if (originalFilename == null) { return false; } String extension = originalFilename.substring( originalFilename.lastIndexOf(\u0026#34;.\u0026#34;) + 1).toLowerCase(); return ALLOWED_EXTENSIONS.contains(extension); } } Step 5: Error Handling Exception Handling S3Exception Class\npackage com.elearning.elearning_backend.Exception; public class S3Exception extends RuntimeException { public S3Exception(String message) { super(message); } public S3Exception(String message, Throwable cause) { super(message, cause); } } Global Exception Handler\n@ControllerAdvice public class GlobalExceptionHandler { @ExceptionHandler(S3Exception.class) public ResponseEntity\u0026lt;ErrorResponse\u0026gt; handleS3Exception(S3Exception ex) { ErrorResponse error = new ErrorResponse( \u0026#34;S3_ERROR\u0026#34;, ex.getMessage(), LocalDateTime.now() ); return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR) .body(error); } @ExceptionHandler(MaxUploadSizeExceededException.class) public ResponseEntity\u0026lt;ErrorResponse\u0026gt; handleMaxUploadSizeExceeded( MaxUploadSizeExceededException ex) { ErrorResponse error = new ErrorResponse( \u0026#34;FILE_TOO_LARGE\u0026#34;, \u0026#34;File size exceeds maximum allowed size\u0026#34;, LocalDateTime.now() ); return ResponseEntity.status(HttpStatus.BAD_REQUEST) .body(error); } } Step 6: File Metadata Management File Information Model FileInfo Entity\n@Entity @Table(name = \u0026#34;file_info\u0026#34;) public class FileInfo { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(nullable = false) private String fileName; @Column(nullable = false) private String originalName; @Column(nullable = false) private String contentType; @Column(nullable = false) private Long fileSize; @Column(nullable = false) private String s3Key; @Column(nullable = false) private String s3Url; @Column(name = \u0026#34;uploaded_by\u0026#34;) private Long uploadedBy; @Column(name = \u0026#34;created_at\u0026#34;) private LocalDateTime createdAt; // Constructors, getters, setters } FileInfo Repository\n@Repository public interface FileInfoRepository extends JpaRepository\u0026lt;FileInfo, Long\u0026gt; { List\u0026lt;FileInfo\u0026gt; findByUploadedBy(Long userId); Optional\u0026lt;FileInfo\u0026gt; findByFileName(String fileName); List\u0026lt;FileInfo\u0026gt; findByContentTypeContaining(String contentType); @Query(\u0026#34;SELECT f FROM FileInfo f WHERE f.createdAt \u0026gt;= :startDate\u0026#34;) List\u0026lt;FileInfo\u0026gt; findFilesUploadedAfter(@Param(\u0026#34;startDate\u0026#34;) LocalDateTime startDate); } Step 7: Enhanced S3Service with Metadata Updated S3Service Enhanced Upload Method\n@Service public class S3Service { private final S3Client s3Client; private final FileInfoRepository fileInfoRepository; private final String bucketName = \u0026#34;elearning-uploads-ap-southeast-1\u0026#34;; public S3Service(S3Client s3Client, FileInfoRepository fileInfoRepository) { this.s3Client = s3Client; this.fileInfoRepository = fileInfoRepository; } public FileInfo uploadFile(MultipartFile file, Long uploadedBy) throws IOException { // Generate unique file name String originalFileName = file.getOriginalFilename(); String fileExtension = originalFileName.substring(originalFileName.lastIndexOf(\u0026#34;.\u0026#34;)); String uniqueFileName = UUID.randomUUID().toString() + fileExtension; // Upload to S3 s3Client.putObject(PutObjectRequest.builder() .bucket(bucketName) .key(uniqueFileName) .contentType(file.getContentType()) .build(), RequestBody.fromBytes(file.getBytes()) ); // Save metadata to database FileInfo fileInfo = new FileInfo(); fileInfo.setFileName(uniqueFileName); fileInfo.setOriginalName(originalFileName); fileInfo.setContentType(file.getContentType()); fileInfo.setFileSize(file.getSize()); fileInfo.setS3Key(uniqueFileName); fileInfo.setS3Url(\u0026#34;https://\u0026#34; + bucketName + \u0026#34;.s3.amazonaws.com/\u0026#34; + uniqueFileName); fileInfo.setUploadedBy(uploadedBy); fileInfo.setCreatedAt(LocalDateTime.now()); return fileInfoRepository.save(fileInfo); } } Step 8: Testing S3 Integration Unit Tests S3Service Test\n@ExtendWith(MockitoExtension.class) class S3ServiceTest { @Mock private S3Client s3Client; @Mock private FileInfoRepository fileInfoRepository; @InjectMocks private S3Service s3Service; @Test void shouldUploadFileSuccessfully() throws IOException { // Given MultipartFile file = mock(MultipartFile.class); when(file.getOriginalFilename()).thenReturn(\u0026#34;test.jpg\u0026#34;); when(file.getContentType()).thenReturn(\u0026#34;image/jpeg\u0026#34;); when(file.getBytes()).thenReturn(\u0026#34;test content\u0026#34;.getBytes()); when(file.getSize()).thenReturn(12L); // When FileInfo result = s3Service.uploadFile(file, 1L); // Then assertThat(result).isNotNull(); assertThat(result.getOriginalName()).isEqualTo(\u0026#34;test.jpg\u0026#34;); assertThat(result.getContentType()).isEqualTo(\u0026#34;image/jpeg\u0026#34;); verify(s3Client).putObject(any(PutObjectRequest.class), any(RequestBody.class)); verify(fileInfoRepository).save(any(FileInfo.class)); } } Integration Test\n@SpringBootTest @AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE) class FileControllerIntegrationTest { @Autowired private TestRestTemplate restTemplate; @Test void shouldUploadFileViaAPI() { // Given MultiValueMap\u0026lt;String, Object\u0026gt; body = new LinkedMultiValueMap\u0026lt;\u0026gt;(); body.add(\u0026#34;file\u0026#34;, new ByteArrayResource(\u0026#34;test content\u0026#34;.getBytes()) { @Override public String getFilename() { return \u0026#34;test.txt\u0026#34;; } }); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.MULTIPART_FORM_DATA); HttpEntity\u0026lt;MultiValueMap\u0026lt;String, Object\u0026gt;\u0026gt; requestEntity = new HttpEntity\u0026lt;\u0026gt;(body, headers); // When ResponseEntity\u0026lt;String\u0026gt; response = restTemplate.postForEntity( \u0026#34;/files/upload\u0026#34;, requestEntity, String.class); // Then assertThat(response.getStatusCode()).isEqualTo(HttpStatus.OK); assertThat(response.getBody()).contains(\u0026#34;s3.amazonaws.com\u0026#34;); } } Step 8: Performance Optimization Async File Processing Async Configuration\n@Configuration @EnableAsync public class AsyncConfig { @Bean(name = \u0026#34;fileProcessingExecutor\u0026#34;) public Executor fileProcessingExecutor() { ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(5); executor.setMaxPoolSize(10); executor.setQueueCapacity(100); executor.setThreadNamePrefix(\u0026#34;FileProcessing-\u0026#34;); executor.initialize(); return executor; } } Async File Upload\n@Service public class S3Service { @Async(\u0026#34;fileProcessingExecutor\u0026#34;) public CompletableFuture\u0026lt;FileInfo\u0026gt; uploadFileAsync(MultipartFile file, Long uploadedBy) { try { FileInfo result = uploadFile(file, uploadedBy); return CompletableFuture.completedFuture(result); } catch (Exception e) { CompletableFuture\u0026lt;FileInfo\u0026gt; future = new CompletableFuture\u0026lt;\u0026gt;(); future.completeExceptionally(e); return future; } } } Troubleshooting Common Issues Access Denied Errors\n# Check IAM permissions aws iam get-user aws iam list-attached-user-policies --user-name [username] # Verify bucket policy aws s3api get-bucket-policy --bucket elearning-uploads-ap-southeast-1 # Test S3 access aws s3 ls s3://elearning-uploads-ap-southeast-1/ File Upload Issues\nCommon Problems: - File size too large - Invalid file type - Network timeout - Insufficient permissions - Bucket not found Solutions: - Check file size limits - Validate file types - Increase timeout values - Verify IAM permissions - Check bucket name Next Steps Với S3 integration đã được thiết lập, chúng ta có thể:\nTích hợp với CloudFront CDN Implement file versioning Add file compression Set up automated backups Key Takeaways AWS SDK v2 cung cấp modern Java API cho S3 S3Service đóng gói tất cả S3 operations FileController cung cấp REST API endpoints Error handling cần thiết cho production use File metadata giúp quản lý files hiệu quả Async processing tối ưu hóa performance "
},
{
	"uri": "//localhost:1313/1-create-new-aws-account/1.2-update-account/",
	"title": "Update Account Information",
	"tags": [],
	"description": "",
	"content": "Update the AWS account name, email address, or password for the root user Editing AWS Account Information To make changes to your AWS account\u0026rsquo;s name, root user\u0026rsquo;s password, or root user\u0026rsquo;s email address, follow the steps below. Your email address and password serve as credentials for signing in as the AWS account root user.\nNote: Changes made to an AWS account may take up to four hours to propagate across all services.\nEditing Account Name, Root User Password, or Email Address Minimum Permissions: To proceed with the following steps, you need to have at least the following IAM permissions:\nYou must log in as the AWS account root user. No additional IAM permissions are required. These steps cannot be performed by an IAM user or role. Sign in to the AWS Management Console using your AWS account\u0026rsquo;s email address and password.\nIn the upper right corner of the console, click on your account name or account number, then select \u0026ldquo;Account.\u0026rdquo;\nOn the Account page, locate \u0026ldquo;Account settings\u0026rdquo; and click \u0026ldquo;Edit.\u0026rdquo; You will be prompted to re-authenticate for security reasons.\nNote: If the \u0026ldquo;Edit\u0026rdquo; option is not visible, it indicates that you are not logged in as the root user of your AWS account. Account settings cannot be modified while signed in as an IAM user or role.\nOn the \u0026ldquo;Update Account Settings\u0026rdquo; page, choose \u0026ldquo;Edit\u0026rdquo; next to the field you wish to update.\nFor Name: On the \u0026ldquo;Update Your Account Name\u0026rdquo; page, enter the new account name in the \u0026ldquo;New account name\u0026rdquo; field, then click \u0026ldquo;Save changes.\u0026rdquo;\nNote: If you encounter issues modifying the AWS account name, check if there\u0026rsquo;s a Service Control Policy (SCP) within AWS Organizations that restricts access to \u0026ldquo;aws-portal\u0026rdquo; or denies the \u0026ldquo;iam:UpdateAccountName\u0026rdquo; action.\nFor Email: On the \u0026ldquo;Update Your Email Address\u0026rdquo; page, provide the required information for \u0026ldquo;New email address,\u0026rdquo; \u0026ldquo;Confirm new email address,\u0026rdquo; and confirm your current password. Afterward, click \u0026ldquo;Save changes.\u0026rdquo; A verification code will be sent to your new email address from \u0026ldquo;no-reply@verify.signin.aws.\u0026rdquo; On the \u0026ldquo;Verify Your New Email Address\u0026rdquo; page, enter the verification code you received via email, then click \u0026ldquo;Save changes.\u0026rdquo;\nNote: The verification code may take up to 5 minutes to arrive. If you don\u0026rsquo;t find the email in your inbox, remember to check your spam and junk folders.\nFor Password: On the \u0026ldquo;Update Your Password\u0026rdquo; page, fill in the fields for \u0026ldquo;Current password,\u0026rdquo; \u0026ldquo;New password,\u0026rdquo; and \u0026ldquo;Confirm new password.\u0026rdquo; Then, click \u0026ldquo;Save changes.\u0026rdquo; For additional guidance and best practices regarding root user password management, refer to Change the Password for the AWS Account Root User.\nOnce you have completed all the desired changes, select \u0026ldquo;Done.\u0026rdquo;\nThat\u0026rsquo;s it! You\u0026rsquo;ve successfully updated your AWS account information.\n"
},
{
	"uri": "//localhost:1313/3-amazon-s3-storage/",
	"title": "Amazon S3 - File Storage &amp; Management",
	"tags": [],
	"description": "",
	"content": "Amazon S3 - File Storage \u0026amp; Management Overview Trong phần này, chúng ta sẽ thiết lập và cấu hình Amazon S3 để quản lý file storage cho e-learning platform. Bạn sẽ học cách tạo S3 buckets, cấu hình security, và tích hợp với ứng dụng Spring Boot để upload/download files. Đặc biệt, chúng ta sẽ tích hợp S3 với CloudFront để tối ưu hóa performance và giảm chi phí.\nSection Contents 3.1 S3 Bucket Setup \u0026amp; Configuration Thiết lập Amazon S3 buckets và cấu hình cơ bản:\nBucket Creation: Tạo và cấu hình S3 buckets với naming convention Bucket Policies: Cấu hình access policies và permissions CORS Configuration: Cross-Origin Resource Sharing setup Versioning \u0026amp; Lifecycle: File versioning và lifecycle management Encryption: Server-side encryption configuration Explore S3 Bucket Setup →\n3.2 Spring Boot S3 Integration Tích hợp Amazon S3 với Spring Boot application:\nAWS SDK Configuration: Cấu hình AWS SDK cho Java S3Service Implementation: Service để upload files lên S3 FileController: REST API endpoints cho file operations File Management: CRUD operations cho files Error Handling: Xử lý lỗi và retry mechanisms Explore Spring Boot Integration →\n3.3 CloudFront CDN Integration Tích hợp CloudFront với S3 để tối ưu hóa delivery:\nCloudFront Distribution: Tạo và cấu hình CDN distribution Origin Configuration: Cấu hình S3 origin cho CloudFront Cache Policies: Tối ưu hóa caching strategies Security: Origin access control và SSL/TLS Performance Monitoring: CloudFront metrics và analytics Explore CloudFront Integration →\nS3 Overview Amazon S3 Benefits Object Storage Service\nScalability: Unlimited storage capacity Durability: 99.999999999% (11 9\u0026rsquo;s) durability Availability: 99.99% availability SLA Security: Built-in security và compliance features Cost-Effective: Pay only for storage used Use Cases for E-Learning\nCourse Content: Video lectures, documents, presentations User Uploads: Assignment submissions, profile pictures Backup Storage: Database backups, system snapshots Static Assets: /images, CSS, JavaScript files Media Files: Audio, video, interactive content S3 Storage Classes Storage Class Selection Standard Storage\nUse Case: Frequently accessed data Availability: 99.99% Durability: 99.999999999% Cost: Most expensive Access Time: Milliseconds Intelligent Tiering\nUse Case: Data with unknown access patterns Availability: 99.9% Durability: 99.999999999% Cost: Automatic cost optimization Access Time: Milliseconds to hours Standard-IA (Infrequent Access)\nUse Case: Infrequently accessed data Availability: 99.9% Durability: 99.999999999% Cost: 40% cheaper than Standard Access Time: Milliseconds Glacier Storage\nUse Case: Long-term archival data Availability: 99.9% Durability: 99.999999999% Cost: 90% cheaper than Standard Access Time: Minutes to hours S3 Security Features Access Control IAM Policies\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::elearning-uploads-*/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:PrincipalTag/Role\u0026#34;: \u0026#34;E-Learning-User\u0026#34; } } } ] } Bucket Policies\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadForGetBucketObjects\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::elearning-uploads-*/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:ResourceType\u0026#34;: \u0026#34;object\u0026#34; } } } ] } Encryption Server-Side Encryption\nDefault encryption: Enable Encryption type: Amazon S3-managed keys (SSE-S3) - OR - Encryption type: AWS KMS keys (SSE-KMS) - OR - Encryption type: Customer-provided keys (SSE-C) Client-Side Encryption\n// Encrypt data before uploading EncryptionMaterials materials = new EncryptionMaterials(kmsKeyId); AmazonS3EncryptionClient encryptionClient = new AmazonS3EncryptionClient( credentials, materials, cryptoConfig); S3 Performance Optimization Performance Features S3 Transfer Acceleration\nEnable: Yes Endpoint: s3-accelerate.amazonaws.com Benefits: - Faster uploads from distant locations - Uses CloudFront edge locations - Automatic fallback to standard S3 Multipart Upload\n// For files larger than 100 MB TransferManager transferManager = TransferManagerBuilder.standard() .withS3Client(s3Client) .build(); Upload upload = transferManager.upload(bucketName, key, file); upload.waitForCompletion(); Parallel Processing\n// Upload multiple files in parallel ExecutorService executor = Executors.newFixedThreadPool(10); List\u0026lt;Future\u0026lt;UploadResult\u0026gt;\u0026gt; futures = new ArrayList\u0026lt;\u0026gt;(); for (File file : files) { futures.add(executor.submit(() -\u0026gt; uploadFile(file))); } S3 Data Management Lifecycle Policies Automated Lifecycle Management\nLifecycle Rule: Course Content Management Actions: - Transition to IA after 30 days - Transition to Glacier after 90 days - Delete after 2555 days (7 years) Filters: - Prefix: courses/ - Tags: content-type=course-material Versioning Configuration\nEnable versioning: Yes Benefits: - Protect against accidental deletion - Rollback to previous versions - Compliance requirements - Cost implications (pay for all versions) Backup and Recovery Cross-Region Replication\nSource bucket: ap-southeast-1 Destination bucket: ap-southeast-2 Replication rules: - Replicate all objects - Replicate delete markers - Replicate existing objects S3 Replication Configuration\n{ \u0026#34;Role\u0026#34;: \u0026#34;arn:aws:iam::123456789012:role/s3-replication-role\u0026#34;, \u0026#34;Rules\u0026#34;: [ { \u0026#34;Status\u0026#34;: \u0026#34;Enabled\u0026#34;, \u0026#34;Priority\u0026#34;: 1, \u0026#34;DeleteMarkerReplication\u0026#34;: { \u0026#34;Status\u0026#34;: \u0026#34;Enabled\u0026#34; }, \u0026#34;Destination\u0026#34;: { \u0026#34;Bucket\u0026#34;: \u0026#34;arn:aws:s3:::elearning-backup-bucket\u0026#34;, \u0026#34;StorageClass\u0026#34;: \u0026#34;STANDARD_IA\u0026#34; } } ] } CloudFront Integration Benefits CDN Advantages Performance Improvement\nGlobal Edge Locations: Content served from nearest location Reduced Latency: Faster file access worldwide Bandwidth Optimization: Reduced origin server load Caching: Intelligent caching strategies Cost Optimization\nReduced Data Transfer: Lower S3 data transfer costs Edge Computing: Lambda@Edge for custom logic Compression: Automatic content compression Intelligent Routing: Route 53 integration Next Steps Trong các phần tiếp theo, chúng ta sẽ:\nThiết lập S3 buckets cụ thể với cấu hình thực tế Cấu hình Spring Boot integration với S3Service Thiết lập CloudFront distribution Implement advanced S3 features Key Takeaways Amazon S3 cung cấp scalable và durable object storage Multiple storage classes cho phép tối ưu hóa chi phí Built-in security với encryption và access control Performance optimization với transfer acceleration và multipart upload CloudFront integration tối ưu hóa content delivery Cost optimization cần thiết cho production workloads "
},
{
	"uri": "//localhost:1313/3-amazon-s3-storage/3.3-cloudfront-integration/",
	"title": "CloudFront CDN Integration",
	"tags": [],
	"description": "",
	"content": "CloudFront CDN Integration Overview Trong phần này, chúng ta sẽ tích hợp Amazon CloudFront với S3 để tối ưu hóa content delivery. CloudFront sẽ hoạt động như một CDN (Content Delivery Network), giúp tăng tốc độ truy cập files từ S3 và giảm chi phí data transfer. Bạn sẽ học cách tạo CloudFront distribution, cấu hình origin access, và tích hợp với Spring Boot application.\nPrerequisites CloudFront Setup Required Services\nAmazon S3: Source bucket đã được cấu hình IAM Permissions: Quyền tạo và quản lý CloudFront distributions SSL Certificate: Domain certificate (nếu sử dụng custom domain) IAM Permissions Required\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudfront:*\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Step 1: Create CloudFront Distribution Distribution Configuration 1. Navigate to CloudFront\nBước 1 — Chuẩn bị S3 bucket Bạn đã có S3 bucket chứa file ảnh rồi (ví dụ: my-project-bucket). Vào S3 → chọn bucket → Properties → kiểm tra Block all public access đang ON. Nếu muốn cho CloudFront truy cập, không cần bật public — ta sẽ dùng Origin Access Control (OAC). 2. Origin Configuration\nOrigin Domain: [Select S3 bucket] - Example: elearning-uploads-ap-southeast-1.s3.ap-southeast-1.amazonaws.com - Or use S3 bucket name: elearning-uploads-ap-southeast-1 Origin Path: [Leave empty] - Root path for all objects - Can specify subfolder if needed Origin Access: Origin access control settings (recommended) - More secure than public bucket access - AWS manages access automatically - Better security control 3. Distribution Settings\nSpecify origin Step 3: Update S3Service for CloudFront CloudFront Integration 1. Update S3Service Configuration\n@Service public class S3Service { private final S3Client s3Client; private final String bucketName = \u0026#34;elearning-uploads-ap-southeast-1\u0026#34;; @Value(\u0026#34;${app.aws.cloudfront.domain:}\u0026#34;) private String cloudfrontDomain; public S3Service(S3Client s3Client) { this.s3Client = s3Client; } public String uploadFile(MultipartFile file) throws IOException { String keyName = file.getOriginalFilename(); String contentType = file.getContentType(); // Upload to S3 s3Client.putObject(PutObjectRequest.builder() .bucket(bucketName) .key(keyName) .contentType(contentType) .build(), RequestBody.fromBytes(file.getBytes()) ); // Return CloudFront URL if available, otherwise S3 URL if (cloudfrontDomain != null \u0026amp;\u0026amp; !cloudfrontDomain.isEmpty()) { return \u0026#34;https://\u0026#34; + cloudfrontDomain + \u0026#34;/\u0026#34; + keyName; } else { return \u0026#34;https://\u0026#34; + bucketName + \u0026#34;.s3.amazonaws.com/\u0026#34; + keyName; } } } 2. Application Properties Configuration\n# CloudFront Configuration app.aws.cloudfront.domain=[YOUR_CLOUDFRONT_DOMAIN] - Example: d2ledyithr93sd.cloudfront.net - Get from CloudFront distribution details - Used for generating file URLs Step 5: CloudFront Distribution Deployment Distribution Status 1. Wait for Deployment\nDeployment Process: - Status: In Progress - Duration: 5-15 minutes - Regions: Global deployment - Edge Locations: 200+ locations worldwide 2. Verify Deployment\nDeployment Complete: - Status: Deployed - Domain Name: [Your CloudFront domain] - Edge Locations: Active - Origin: Connected to S3 Step 6: Test CloudFront Integration File Access Testing 1. Test CloudFront URL\n# Test CloudFront access curl -I \u0026#34;https://[CLOUDFRONT_DOMAIN]/[FILENAME]\u0026#34; # Compare with S3 direct access curl -I \u0026#34;https://[BUCKET_NAME].s3.amazonaws.com/[FILENAME]\u0026#34; # Check response headers curl -v \u0026#34;https://[CLOUDFRONT_DOMAIN]/[FILENAME]\u0026#34; 2. Performance Comparison\nPerformance Metrics: - S3 Direct Access: Higher latency - CloudFront Access: Lower latency - Cache Hit: Faster response - Cache Miss: S3 fallback 2.Test chạy thử trên postman Next Steps Với CloudFront CDN đã được tích hợp, chúng ta có thể:\nMonitor performance metrics Optimize cache policies Implement custom behaviors với Lambda@Edge Scale globally với edge locations Key Takeaways CloudFront CDN tối ưu hóa content delivery worldwide Origin Access Control cung cấp security cho S3 bucket Cache Policies ảnh hưởng đến performance và cost Lambda@Edge cho phép custom logic tại edge locations Monitoring cần thiết cho performance optimization Cost optimization với price class và data transfer management "
},
{
	"uri": "//localhost:1313/2-rds-mysql-springboot/2.3-database-migration/",
	"title": "Database Migration with Flyway",
	"tags": [],
	"description": "",
	"content": "Database Migration with Flyway Overview Trong phần này, chúng ta sẽ học cách sử dụng Flyway để quản lý database migration một cách tự động và an toàn. Flyway sẽ giúp bạn version control database schema, tự động chạy migration scripts, và đảm bảo consistency giữa các môi trường development, staging, và production.\nPrerequisites Flyway Setup Required Dependencies\nFlyway Core: Core migration engine Flyway MySQL: MySQL-specific support Spring Boot Flyway: Spring Boot integration Maven Dependencies\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.flywaydb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flyway-core\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.flywaydb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flyway-mysql\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Step 1: Flyway Configuration Basic Configuration Application Properties\n# Flyway Configuration spring.flyway.enabled=true spring.flyway.baseline-on-migrate=true spring.flyway.baseline-version=0 spring.flyway.baseline-description=Initial baseline spring.flyway.locations=classpath:db/migration spring.flyway.table=flyway_schema_history spring.flyway.validate-on-migrate=false spring.flyway.clean-disabled=true spring.flyway.out-of-order=true spring.flyway.mixed=true Console Screenshot: Chụp màn hình Flyway configuration trong application.properties\nConfiguration Parameters Explanation\nenabled=true: - Kích hoạt Flyway migration - Tự động chạy khi application start baseline-on-migrate=true: - Tự động tạo baseline nếu database đã có data - Hữu ích cho existing databases - Prevents migration errors locations=classpath:db/migration: - Thư mục chứa migration scripts - Default: src/main/resources/db/migration - Có thể thêm multiple locations table=flyway_schema_history: - Bảng lưu trữ migration history - Tracking tất cả migrations đã chạy - Không nên thay đổi tên bảng này Step 2: Migration Scripts Structure File Naming Convention Standard Naming Pattern\nMigration Script Format: - V[version]__[description].sql - V1__Create_users_table.sql - V2__Add_email_index.sql - V3__Create_courses_table.sql - V4__Add_enrollment_relationship.sql Version Numbering Strategies: - Sequential: V1, V2, V3... - Minor versions: V1.1, V1.2... - Date-based: V20240101__Initial_schema.sql - Semantic: V1.0.0__Initial_release.sql File Organization\nDirectory Structure: src/main/resources/ └── db/ └── migration/ ├── V1__Create_users_table.sql ├── V2__Add_email_index.sql ├── V3__Create_courses_table.sql └── V4__Add_enrollment_relationship.sql Alternative Locations: - classpath:db/migration - classpath:db/migration/mysql - filesystem:/path/to/migrations - s3://bucket/migrations Step 3: Creating Migration Scripts Initial Schema Migration V1__Create_users_table.sql\n-- Create users table CREATE TABLE users ( id BIGINT AUTO_INCREMENT PRIMARY KEY, email VARCHAR(255) NOT NULL UNIQUE, password_hash VARCHAR(255) NOT NULL, first_name VARCHAR(100) NOT NULL, last_name VARCHAR(100) NOT NULL, role ENUM(\u0026#39;ADMIN\u0026#39;, \u0026#39;TEACHER\u0026#39;, \u0026#39;STUDENT\u0026#39;) NOT NULL DEFAULT \u0026#39;STUDENT\u0026#39;, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, INDEX idx_users_email (email), INDEX idx_users_role (role), INDEX idx_users_created_at (created_at) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci; -- Insert default admin user INSERT INTO users (email, password_hash, first_name, last_name, role) VALUES (\u0026#39;admin@elearning.com\u0026#39;, \u0026#39;$2a$12$...\u0026#39;, \u0026#39;Admin\u0026#39;, \u0026#39;User\u0026#39;, \u0026#39;ADMIN\u0026#39;); V2__Add_email_index.sql\n-- Add unique constraint to email ALTER TABLE users ADD CONSTRAINT uk_users_email UNIQUE (email); -- Add additional indexes for performance CREATE INDEX idx_users_role_created_at ON users(role, created_at); CREATE INDEX idx_users_first_name_last_name ON users(first_name, last_name); V3__Create_courses_table.sql\n-- Create courses table CREATE TABLE courses ( id BIGINT AUTO_INCREMENT PRIMARY KEY, title VARCHAR(255) NOT NULL, description TEXT, category VARCHAR(100), difficulty ENUM(\u0026#39;BEGINNER\u0026#39;, \u0026#39;INTERMEDIATE\u0026#39;, \u0026#39;ADVANCED\u0026#39;) DEFAULT \u0026#39;BEGINNER\u0026#39;, estimated_hours INT DEFAULT 0, price DECIMAL(10,2) DEFAULT 0.00, status ENUM(\u0026#39;DRAFT\u0026#39;, \u0026#39;PUBLISHED\u0026#39;, \u0026#39;ARCHIVED\u0026#39;) DEFAULT \u0026#39;DRAFT\u0026#39;, teacher_id BIGINT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, FOREIGN KEY (teacher_id) REFERENCES users(id) ON DELETE SET NULL, INDEX idx_courses_title (title), INDEX idx_courses_category (category), INDEX idx_courses_status (status), INDEX idx_courses_teacher_id (teacher_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci; Step 4: Advanced Migration Scripts Data Migration Scripts V4__Seed_initial_data.sql\n-- Insert sample courses INSERT INTO courses (title, description, category, difficulty, estimated_hours, price, status, teacher_id) VALUES (\u0026#39;Introduction to Spring Boot\u0026#39;, \u0026#39;Learn Spring Boot fundamentals\u0026#39;, \u0026#39;PROGRAMMING\u0026#39;, \u0026#39;BEGINNER\u0026#39;, 20, 99.99, \u0026#39;PUBLISHED\u0026#39;, 1), (\u0026#39;Advanced Java Development\u0026#39;, \u0026#39;Master Java programming\u0026#39;, \u0026#39;PROGRAMMING\u0026#39;, \u0026#39;ADVANCED\u0026#39;, 40, 199.99, \u0026#39;PUBLISHED\u0026#39;, 1), (\u0026#39;Web Development Basics\u0026#39;, \u0026#39;HTML, CSS, JavaScript fundamentals\u0026#39;, \u0026#39;WEB_DEVELOPMENT\u0026#39;, \u0026#39;BEGINNER\u0026#39;, 30, 149.99, \u0026#39;PUBLISHED\u0026#39;, 1); -- Insert sample users INSERT INTO users (email, password_hash, first_name, last_name, role) VALUES (\u0026#39;teacher1@elearning.com\u0026#39;, \u0026#39;$2a$12$...\u0026#39;, \u0026#39;Jane\u0026#39;, \u0026#39;Smith\u0026#39;, \u0026#39;TEACHER\u0026#39;), (\u0026#39;student1@elearning.com\u0026#39;, \u0026#39;$2a$12$...\u0026#39;, \u0026#39;John\u0026#39;, \u0026#39;Doe\u0026#39;, \u0026#39;STUDENT\u0026#39;), (\u0026#39;student2@elearning.com\u0026#39;, \u0026#39;$2a$12$...\u0026#39;, \u0026#39;Alice\u0026#39;, \u0026#39;Johnson\u0026#39;, \u0026#39;STUDENT\u0026#39;); V5__Add_enrollment_table.sql\n-- Create enrollments table CREATE TABLE enrollments ( id BIGINT AUTO_INCREMENT PRIMARY KEY, user_id BIGINT NOT NULL, course_id BIGINT NOT NULL, enrolled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, progress DECIMAL(5,2) DEFAULT 0.00, status ENUM(\u0026#39;ACTIVE\u0026#39;, \u0026#39;COMPLETED\u0026#39;, \u0026#39;CANCELLED\u0026#39;) DEFAULT \u0026#39;ACTIVE\u0026#39;, completed_at TIMESTAMP NULL, FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE, FOREIGN KEY (course_id) REFERENCES courses(id) ON DELETE CASCADE, UNIQUE KEY uk_user_course (user_id, course_id), INDEX idx_enrollments_user_id (user_id), INDEX idx_enrollments_course_id (course_id), INDEX idx_enrollments_status (status) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci; Step 5: Running Migrations Automatic Migration Application Startup\nMigration Process: - Application starts - Flyway checks database schema - Compares with migration scripts - Runs pending migrations automatically - Updates flyway_schema_history table - Application continues startup Manual Migration Commands\n# Check migration status mvn flyway:info # Run migrations manually mvn flyway:migrate # Validate migrations mvn flyway:validate # Repair migrations if needed mvn flyway:repair # Clean database (development only) mvn flyway:clean Step 6: Migration Management Version Control Integration Git Workflow\nDevelopment Process: 1. Create feature branch 2. Write migration script 3. Test migration locally 4. Commit migration script 5. Push to remote branch 6. Create pull request 7. Code review 8. Merge to main branch 9. Deploy to production Migration Script Review\nReview Checklist: - Naming convention follows standard - SQL syntax is correct - Indexes are appropriate - Foreign keys are properly defined - Data types are suitable - Default values are reasonable - Rollback strategy is considered Step 7: Rollback Strategies Rollback Approaches Version-based Rollback\n-- Create rollback script V5.1__Rollback_enrollment_table.sql DROP TABLE IF EXISTS enrollments; -- Or create V6__Remove_enrollment_table.sql DROP TABLE enrollments; Data Preservation\n-- Before dropping table, backup data CREATE TABLE enrollments_backup AS SELECT * FROM enrollments; -- Or export to file SELECT * FROM enrollments INTO OUTFILE \u0026#39;/tmp/enrollments_backup.csv\u0026#39; FIELDS TERMINATED BY \u0026#39;,\u0026#39; ENCLOSED BY \u0026#39;\u0026#34;\u0026#39; LINES TERMINATED BY \u0026#39;\\n\u0026#39;; Step 8: Testing Migrations Test Environment Setup Test Database Configuration\n# application-test.properties spring.datasource.url=jdbc:h2:mem:testdb spring.datasource.driver-class-name=org.h2.Driver spring.flyway.enabled=true spring.flyway.locations=classpath:db/migration Migration Testing\n@SpringBootTest @ActiveProfiles(\u0026#34;test\u0026#34;) class FlywayMigrationTest { @Autowired private JdbcTemplate jdbcTemplate; @Test void shouldCreateUsersTable() { // Given String sql = \u0026#34;SELECT COUNT(*) FROM information_schema.tables WHERE table_name = \u0026#39;users\u0026#39;\u0026#34;; // When int count = jdbcTemplate.queryForObject(sql, Integer.class); // Then assertThat(count).isEqualTo(1); } @Test void shouldHaveCorrectUserColumns() { // Given String sql = \u0026#34;SELECT column_name FROM information_schema.columns WHERE table_name = \u0026#39;users\u0026#39; ORDER BY ordinal_position\u0026#34;; // When List\u0026lt;String\u0026gt; columns = jdbcTemplate.queryForList(sql, String.class); // Then assertThat(columns).contains(\u0026#34;id\u0026#34;, \u0026#34;email\u0026#34;, \u0026#34;password_hash\u0026#34;, \u0026#34;first_name\u0026#34;, \u0026#34;last_name\u0026#34;, \u0026#34;role\u0026#34;); } } Step 9: Production Deployment Production Considerations Migration Safety\nProduction Guidelines: - Always backup database before migration - Test migrations on staging environment - Use maintenance window for major changes - Monitor migration execution - Have rollback plan ready - Document all changes Deployment Process\n# Production deployment steps 1. Backup production database 2. Deploy application with new migrations 3. Monitor migration execution 4. Verify database schema 5. Run smoke tests 6. Monitor application health 7. Rollback if issues occur Step 10: Monitoring and Maintenance Migration History Schema History Table\n-- Check migration history SELECT * FROM flyway_schema_history ORDER BY installed_rank DESC; -- Check current schema version SELECT version FROM flyway_schema_history WHERE installed_rank = (SELECT MAX(installed_rank) FROM flyway_schema_history); Performance Monitoring\nMonitoring Metrics: - Migration execution time - Number of pending migrations - Migration success rate - Database schema changes - Rollback frequency Troubleshooting Common Issues Migration Failures\n# Check migration status mvn flyway:info # View detailed error logs tail -f application.log | grep -i flyway # Repair corrupted migrations mvn flyway:repair # Check database connectivity mysql -h [RDS_ENDPOINT] -u [USERNAME] -p Version Conflicts\nCommon Issues: - Duplicate version numbers - Missing migration scripts - Database schema mismatch - Permission issues - Network connectivity problems Solutions: - Check migration script naming - Verify database permissions - Test connectivity - Review error logs Next Steps Với Flyway migration đã được thiết lập, chúng ta có thể:\nTạo và quản lý complex migration scripts Implement automated deployment pipeline Monitor migration performance Handle production rollbacks Key Takeaways Flyway migration cung cấp automated database schema management Version control cho database changes đảm bảo consistency Rollback strategies cần thiết cho production safety Testing migrations đảm bảo reliability Production deployment cần careful planning và monitoring Migration history cung cấp audit trail cho database changes "
},
{
	"uri": "//localhost:1313/1-create-new-aws-account/1.3-aws-account-alias/",
	"title": "AWS Account Alias",
	"tags": [],
	"description": "",
	"content": "Managing AWS Account Aliases for IAM User Sign-In The AWS account root user and AWS Identity and Access Management (IAM) users in the account sign in using a web URL.\nIf you want the URL for your IAM users to contain your company name (or another easy-to-remember identifier) instead of the AWS account ID, you can create an account alias. This section provides information about AWS account aliases and lists the API operations that you can use to create an alias.\nThe sign-in page URL for your account\u0026rsquo;s IAM users has the following format, by default:\nhttps://Your_Account_ID.signin.aws.amazon.com/console/ If you create an AWS account alias for your AWS account ID, the IAM user sign-in page URL looks like the following example:\nhttps://Your_Account_Alias.signin.aws.amazon.com/console/ The original URL containing your AWS account ID remains active and can still be used after you create your AWS account alias.\nTip To create a bookmark for your account sign-in page in your web browser, we recommend that you manually type the sign-in URL in the bookmark entry. Don\u0026rsquo;t use your web browser\u0026rsquo;s \u0026ldquo;bookmark this page\u0026rdquo; feature, as it can capture session-specific information that might interfere with future visits to the page.\nConsiderations Your AWS account can have only one alias. Creating a new alias will overwrite the previous one, and the URL containing the previous alias will stop working. The account alias must be unique across all Amazon Web Services products. The alias can only contain lowercase letters, digits, and hyphens. Create or Edit an Account Alias Minimum Permissions To perform the following steps, you must have at least the following IAM permissions:\niam:ListAccountAliases iam:CreateAccountAlias Sign in to the AWS Management Console as either the AWS account root user or as an IAM user or role that has the minimum permissions.\nOpen the IAM console at https://console.aws.amazon.com/iam/.\nIn the navigation pane, choose Dashboard.\nIn the right-hand pane under AWS account, next to Account Alias, choose Create. If an alias already exists, then choose Edit.\nIn the dialog box, enter the new or updated name you want to use for your alias, then choose Save changes.\nNote: You can have only one alias associated with your AWS account at a time. If you create a new alias, the previous alias is removed, and the sign-in URL that was associated with the previous alias stops working.\nDelete an Account Alias Minimum Permissions To perform the following steps, you must have at least the following IAM permissions:\niam:ListAccountAliases iam:CreateAccountAlias iam:DeleteAccountAlias Sign in to the AWS Management Console as either the AWS account root user or as an IAM user or role that has the minimum permissions.\nOpen the IAM console at https://console.aws.amazon.com/iam/.\nIn the navigation pane, choose Dashboard.\nIn the right-hand pane under AWS account, next to Account Alias, choose Delete.\n"
},
{
	"uri": "//localhost:1313/4-mongodb-atlas/",
	"title": "MongoDB Atlas - Cloud Database Service",
	"tags": [],
	"description": "",
	"content": "MongoDB Atlas - Cloud Database Service Overview Trong phần này, chúng ta sẽ thiết lập và cấu hình MongoDB Atlas để sử dụng làm cloud database service cho e-learning platform. Bạn sẽ học cách tạo cluster, cấu hình security, và tích hợp với ứng dụng Spring Boot. MongoDB Atlas sẽ cung cấp managed MongoDB service với high availability và global distribution.\nSection Contents 4.1 MongoDB Atlas Setup \u0026amp; Configuration Thiết lập MongoDB Atlas cluster và cấu hình cơ bản:\nCluster Creation: Tạo và cấu hình MongoDB cluster Network Access: Cấu hình IP whitelist và VPC peering Database Access: Tạo database users và roles Cluster Configuration: Instance size và storage configuration Backup \u0026amp; Monitoring: Automated backup và monitoring setup Explore Atlas Setup →\n4.2 Spring Boot MongoDB Integration Tích hợp MongoDB Atlas với Spring Boot application:\nMongoDB Driver Configuration: Cấu hình MongoDB Java driver Spring Data MongoDB: Cấu hình Spring Data MongoDB Connection Management: Connection pooling và retry logic Data Models: MongoDB document models và repositories Performance Optimization: Indexing và query optimization Explore Spring Boot Integration →\n4.3 MongoDB Data Management Quản lý dữ liệu và performance với MongoDB:\nDocument Design: Thiết kế MongoDB documents cho e-learning Indexing Strategy: Tối ưu hóa queries với indexes Aggregation Pipeline: Complex data processing Data Validation: Schema validation và data integrity Performance Monitoring: Query optimization và monitoring Explore Data Management →\nMongoDB Atlas Overview Cloud Database Benefits Managed MongoDB Service\nAutomated Operations: Atlas tự động quản lý database operations Global Distribution: Deploy clusters worldwide Built-in Security: Enterprise-grade security features Scalability: Auto-scaling và manual scaling options Monitoring: Real-time monitoring và alerting Use Cases for E-Learning\nUser Profiles: Flexible user data storage Course Content: Rich document storage Learning Analytics: Student progress tracking Real-time Data: Chat messages và notifications Content Metadata: Flexible content organization Atlas Cluster Types Shared Clusters (Free Tier) M0 Sandbox\nUse Case: Development và testing Storage: 512 MB RAM: Shared vCPU: Shared Cost: Free Limitations: No dedicated resources M2/M5 Shared\nUse Case: Small production workloads Storage: 2-5 GB RAM: Shared vCPU: Shared Cost: $9-25/month Limitations: Limited performance Dedicated Clusters M10+ Dedicated\nUse Case: Production workloads Storage: 10+ GB RAM: Dedicated vCPU: Dedicated Cost: $57+/month Benefits: Predictable performance M30+ Dedicated\nUse Case: High-performance applications Storage: 30+ GB RAM: Dedicated vCPU: Dedicated Cost: $171+/month Benefits: High performance và reliability Atlas Security Features Network Security IP Access List\nIP Addresses: - 192.168.1.0/24 (Office network) - 10.0.0.0/8 (VPC CIDR) - 0.0.0.0/0 (Public access - not recommended for production) VPC Peering: - AWS VPC: vpc-12345678 - Atlas VPC: vpc-atlas-87654321 - Route tables: Configure routing Private Endpoint\nAWS PrivateLink: - VPC Endpoint: vpce-12345678 - Service: com.amazonaws.vpce.us-east-1.vpce-svc-12345678 - Security Groups: [Your security group] - Subnets: [Private subnets] Database Security Database Users\n// Create application user db.createUser({ user: \u0026#34;elearning_user\u0026#34;, pwd: \u0026#34;secure_password_123\u0026#34;, roles: [ { role: \u0026#34;readWrite\u0026#34;, db: \u0026#34;elearning\u0026#34; }, { role: \u0026#34;dbAdmin\u0026#34;, db: \u0026#34;elearning\u0026#34; } ] }) // Create read-only user for analytics db.createUser({ user: \u0026#34;analytics_user\u0026#34;, pwd: \u0026#34;analytics_password_456\u0026#34;, roles: [ { role: \u0026#34;read\u0026#34;, db: \u0026#34;elearning\u0026#34; } ] }) Database Roles\n// Custom role for course management db.createRole({ role: \u0026#34;course_manager\u0026#34;, privileges: [ { resource: { db: \u0026#34;elearning\u0026#34;, collection: \u0026#34;courses\u0026#34; }, actions: [\u0026#34;find\u0026#34;, \u0026#34;insert\u0026#34;, \u0026#34;update\u0026#34;, \u0026#34;delete\u0026#34;] }, { resource: { db: \u0026#34;elearning\u0026#34;, collection: \u0026#34;lessons\u0026#34; }, actions: [\u0026#34;find\u0026#34;, \u0026#34;insert\u0026#34;, \u0026#34;update\u0026#34;, \u0026#34;delete\u0026#34;] } ], roles: [] }) Atlas Configuration Cluster Configuration Instance Size Selection\nDevelopment Environment: - Instance Size: M0 (Free) hoặc M2 ($9/month) - Storage: 512 MB - 2 GB - RAM: Shared - vCPU: Shared Production Environment: - Instance Size: M10+ ($57+/month) - Storage: 10+ GB - RAM: Dedicated - vCPU: Dedicated - Backup: Daily snapshots Storage Configuration\nStorage Engine: WiredTiger Storage Size: Auto-scaling enabled - Minimum: 10 GB - Maximum: 100 GB - Auto-scaling threshold: 80% Backup Configuration: - Backup Frequency: Daily - Retention: 7 days - Point-in-time recovery: Enabled Advanced Configuration Performance Advisor\nEnable Performance Advisor: Yes Monitoring: - Slow queries - Missing indexes - Schema suggestions - Performance recommendations Index Suggestions: - Automatic index recommendations - Performance impact analysis - Index creation assistance Real-time Performance Panel\nMetrics Displayed: - Operations per second - Query performance - Connection count - Memory usage - Storage usage - Network I/O Spring Boot Integration MongoDB Driver Configuration Maven Dependencies\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mongodb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mongodb-driver-sync\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.8.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-mongodb\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Application Properties\n# MongoDB Atlas Connection spring.data.mongodb.uri=mongodb+srv://elearning_user:secure_password_123@cluster0.abc123.mongodb.net/elearning?retryWrites=true\u0026amp;w=majority # Connection Pool Settings spring.data.mongodb.connection-pool.max-size=100 spring.data.mongodb.connection-pool.min-size=5 spring.data.mongodb.connection-pool.max-wait-time=30000 # SSL Configuration spring.data.mongodb.ssl.enabled=true spring.data.mongodb.ssl.invalid-host-name-allowed=false Spring Data MongoDB Configuration Configuration Class\n@Configuration @EnableMongoRepositories(basePackages = \u0026#34;com.elearning.repository\u0026#34;) public class MongoConfig extends AbstractMongoClientConfiguration { @Value(\u0026#34;${spring.data.mongodb.uri}\u0026#34;) private String mongoUri; @Override protected String getDatabaseName() { return \u0026#34;elearning\u0026#34;; } @Override public MongoClient mongoClient() { return MongoClients.create(mongoUri); } @Bean public MongoTemplate mongoTemplate() throws Exception { return new MongoTemplate(mongoClient(), getDatabaseName()); } } Repository Configuration\n@Repository public interface UserRepository extends MongoRepository\u0026lt;User, String\u0026gt; { Optional\u0026lt;User\u0026gt; findByEmail(String email); List\u0026lt;User\u0026gt; findByRole(UserRole role); @Query(\u0026#34;{ \u0026#39;profile.firstName\u0026#39;: { $regex: ?0, $options: \u0026#39;i\u0026#39; } }\u0026#34;) List\u0026lt;User\u0026gt; findByFirstNameContainingIgnoreCase(String firstName); @Query(\u0026#34;{ \u0026#39;createdAt\u0026#39;: { $gte: ?0, $lte: ?1 } }\u0026#34;) List\u0026lt;User\u0026gt; findByCreatedAtBetween(LocalDateTime start, LocalDateTime end); } Data Modeling Document Structure User Document\n{ \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;507f1f77bcf86cd799439011\u0026#34;), \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;passwordHash\u0026#34;: \u0026#34;$2a$12$...\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;STUDENT\u0026#34;, \u0026#34;profile\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;avatar\u0026#34;: \u0026#34;https://s3.amazonaws.com/avatars/john-doe.jpg\u0026#34;, \u0026#34;bio\u0026#34;: \u0026#34;Student interested in programming\u0026#34;, \u0026#34;preferences\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;en\u0026#34;, \u0026#34;timezone\u0026#34;: \u0026#34;UTC\u0026#34;, \u0026#34;notifications\u0026#34;: true } }, \u0026#34;enrollments\u0026#34;: [ { \u0026#34;courseId\u0026#34;: ObjectId(\u0026#34;507f1f77bcf86cd799439012\u0026#34;), \u0026#34;enrolledAt\u0026#34;: ISODate(\u0026#34;2025-01-11T10:00:00Z\u0026#34;), \u0026#34;progress\u0026#34;: 0.75, \u0026#34;lastAccessed\u0026#34;: ISODate(\u0026#34;2025-01-11T15:30:00Z\u0026#34;) } ], \u0026#34;createdAt\u0026#34;: ISODate(\u0026#34;2025-01-01T00:00:00Z\u0026#34;), \u0026#34;updatedAt\u0026#34;: ISODate(\u0026#34;2025-01-11T15:30:00Z\u0026#34;) } Course Document\n{ \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;507f1f77bcf86cd799439012\u0026#34;), \u0026#34;title\u0026#34;: \u0026#34;Introduction to Spring Boot\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Learn Spring Boot fundamentals\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;PROGRAMMING\u0026#34;, \u0026#34;difficulty\u0026#34;: \u0026#34;BEGINNER\u0026#34;, \u0026#34;estimatedHours\u0026#34;: 20, \u0026#34;price\u0026#34;: 99.99, \u0026#34;teacher\u0026#34;: { \u0026#34;id\u0026#34;: ObjectId(\u0026#34;507f1f77bcf86cd799439013\u0026#34;), \u0026#34;name\u0026#34;: \u0026#34;Jane Smith\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;jane@example.com\u0026#34; }, \u0026#34;modules\u0026#34;: [ { \u0026#34;id\u0026#34;: ObjectId(\u0026#34;507f1f77bcf86cd799439014\u0026#34;), \u0026#34;title\u0026#34;: \u0026#34;Getting Started\u0026#34;, \u0026#34;order\u0026#34;: 1, \u0026#34;lessons\u0026#34;: [ { \u0026#34;id\u0026#34;: ObjectId(\u0026#34;507f1f77bcf86cd799439015\u0026#34;), \u0026#34;title\u0026#34;: \u0026#34;Spring Boot Overview\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Introduction to Spring Boot...\u0026#34;, \u0026#34;duration\u0026#34;: 30, \u0026#34;type\u0026#34;: \u0026#34;VIDEO\u0026#34; } ] } ], \u0026#34;tags\u0026#34;: [\u0026#34;spring\u0026#34;, \u0026#34;java\u0026#34;, \u0026#34;backend\u0026#34;], \u0026#34;status\u0026#34;: \u0026#34;PUBLISHED\u0026#34;, \u0026#34;createdAt\u0026#34;: ISODate(\u0026#34;2025-01-01T00:00:00Z\u0026#34;), \u0026#34;updatedAt\u0026#34;: ISODate(\u0026#34;2025-01-11T10:00:00Z\u0026#34;) } Performance Optimization Indexing Strategy Single Field Indexes\n// Email index for user lookup db.users.createIndex({ \u0026#34;email\u0026#34;: 1 }, { unique: true }) // Role index for role-based queries db.users.createIndex({ \u0026#34;role\u0026#34;: 1 }) // Created date index for time-based queries db.users.createIndex({ \u0026#34;createdAt\u0026#34;: -1 }) Compound Indexes\n// Course search index db.courses.createIndex({ \u0026#34;category\u0026#34;: 1, \u0026#34;difficulty\u0026#34;: 1, \u0026#34;status\u0026#34;: 1 }) // User enrollment index db.users.createIndex({ \u0026#34;enrollments.courseId\u0026#34;: 1, \u0026#34;enrollments.progress\u0026#34;: -1 }) Text Indexes\n// Full-text search on course content db.courses.createIndex({ \u0026#34;title\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;tags\u0026#34;: \u0026#34;text\u0026#34; }, { weights: { title: 10, description: 5, tags: 3 } }) Query Optimization Efficient Queries\n// Use projection to limit returned fields db.users.find( { \u0026#34;role\u0026#34;: \u0026#34;STUDENT\u0026#34; }, { \u0026#34;email\u0026#34;: 1, \u0026#34;profile.firstName\u0026#34;: 1, \u0026#34;profile.lastName\u0026#34;: 1 } ) // Use aggregation for complex queries db.courses.aggregate([ { $match: { \u0026#34;status\u0026#34;: \u0026#34;PUBLISHED\u0026#34; } }, { $group: { _id: \u0026#34;$category\u0026#34;, count: { $sum: 1 }, avgPrice: { $avg: \u0026#34;$price\u0026#34; } }}, { $sort: { \u0026#34;count\u0026#34;: -1 } } ]) Monitoring and Analytics Atlas Monitoring Performance Metrics\nDatabase Metrics: - Operations per second - Query performance - Connection count - Memory usage - Storage usage Cluster Metrics: - CPU usage - Memory usage - Network I/O - Disk I/O - Replication lag Alerting Configuration\nCPU Usage Alert: - Metric: CPU Usage - Threshold: 80% - Duration: 5 minutes - Action: Email notification Memory Usage Alert: - Metric: Memory Usage - Threshold: 85% - Duration: 5 minutes - Action: Slack notification Connection Count Alert: - Metric: Connection Count - Threshold: 90% of max connections - Duration: 2 minutes - Action: PagerDuty alert Cost Optimization Pricing Structure Cluster Pricing\nShared Clusters: - M0: Free - M2: $9/month - M5: $25/month Dedicated Clusters: - M10: $57/month - M20: $114/month - M30: $171/month - M40: $228/month Cost Optimization Strategies\nResource Optimization: - Right-size instances - Use auto-scaling - Monitor resource usage - Clean up unused data Storage Optimization: - Enable compression - Use appropriate indexes - Archive old data - Regular data cleanup Next Steps Trong các phần tiếp theo, chúng ta sẽ:\nThiết lập MongoDB Atlas cluster cụ thể Cấu hình Spring Boot integration Implement data models và repositories Thiết lập monitoring và optimization Key Takeaways MongoDB Atlas cung cấp managed MongoDB service với global distribution Multiple cluster types phù hợp với các workload khác nhau Built-in security với network access control và database authentication Performance optimization với indexing và query optimization Monitoring và alerting cung cấp real-time insights Cost optimization cần thiết cho production workloads "
},
{
	"uri": "//localhost:1313/1-create-new-aws-account/1.4-close-account/",
	"title": "Close Account",
	"tags": [],
	"description": "",
	"content": "Close a standalone AWS account Considerations before you close your AWS account Before closing your AWS account, consider the following:\nYour agreement with AWS Closing your AWS account serves as notice to us that you want to cancel the AWS customer agreement or other agreement with AWS that governs your AWS account, solely with respect to this specific AWS account. If you reopen your AWS account during the post-closure period (within 90 days after you close the account), you agree that the same agreement terms govern your access to and use of the service offerings through your reopened AWS account.\nAWS Management Console access Your access to the AWS Management Console for a closed AWS account is restricted. During the post-closure period, you can still sign in to your AWS account to view your past billing information and access AWS Support. You can\u0026rsquo;t access any other AWS services or start any new AWS services in the closed account.\nFind and terminate active resources To prevent unexpected charges, prior to closing your account, we recommended that you first review and terminate all applicable resources currently running in the account.\nLog in to the AWS Management Console. On the navigation pane, choose Services. On the Services page, search for Resource Groups. Under Tag Editor, in Regions, select the regions where you have created resources, or choose All regions. In Resource types, select All supported resource types. Choose Search Resources. If search results appear, then there are still active resources on the account. Note: AWS Resource Groups search results don\u0026rsquo;t show AWS Marketplace subscriptions. To manage subscriptions, see Managing your software.\nYou should archive your content and delete the resources where appropriate. For additional instructions on how to retrieve your content, see the documentation for that service.\nFor more information, see How do I check for active resources that I no longer need on my AWS account?\nExisting content and services still in use after closing After the post-closure period, AWS automatically deletes any remaining content in your AWS account, and attempts to terminate any AWS services that are still in use. For more information about the post-closure period, see Accessing your AWS account after you close it.\nYour payment method We charge you through your designated payment method for any usage fees incurred before you closed your AWS account. We issue you any refunds that might be due through that same payment method. If you have active subscriptions (such as a Reserved Instance that you pay for monthly), even after your account is closed, you might continue to be charged for the subscription through your designated payment method until the subscription expires or is sold according to the terms governing the subscription. These charges and refunds might occur after you close your account.\nIn addition, if you reopen your account, you might be charged for the cost of running AWS services (that you didn\u0026rsquo;t stop before closing your account) during the post-closure period. Closing your AWS account doesn\u0026rsquo;t affect payment methods that you use on Amazon.com or other Amazon websites.\nOn-Demand charges During the post-closure period, billing for On-Demand charges stops. However, you\u0026rsquo;re billed for any usage that has accrued up until the time you closed your account. You\u0026rsquo;ll be charged for that usage at the beginning of the next month. In addition, if you purchased any subscriptions with ongoing payment obligations, you might continue to be charged for them after your account is closed.\nImportant: You will continue to generate costs if you don\u0026rsquo;t stop or delete your resources.\nDomains registered with Amazon Route 53 Domains that are registered with Route 53 are not deleted automatically. When you close your AWS account, you have three options:\nYou can disable automatic renewal, and the domains are automatically deleted when the registration period expires. For more information, see Enabling or Disabling Automatic Renewal for a Domain.\nYou can transfer the domains to another AWS account. For more information, see Transferring a Domain to a Different AWS Account.\nYou can transfer the domains to another domain registrar. For more information, see Transferring a Domain from Route 53 to Another Registrar.\nIf you already closed the account, you can open a case with AWS Support to get help with disabling automatic renewal or transferring your domains. For more information, see Contacting AWS Support About Domain Registration Issues. There is no charge to open a case for domain registration issues.\nCharges if you reopen your AWS account If you reopen your AWS account during the post-closure period, you might be billed for the cost of any AWS services that aren\u0026rsquo;t stopped or resources that aren\u0026rsquo;t deleted before you close your account.\nExample: You reopen your AWS account 30 days after closure. Your AWS account had only an active t2.micro Amazon EC2 instance at closure. For this example, imagine that the price for a t2.micro Amazon EC2 instance in your AWS Region is $0.01 per hour. In this case, you might be charged for 30 days x 24 hours x $0.01 per hour = $7.20 for your AWS services.\nCross-account access to the account you’re closing After you close your AWS account, any access requests to your closed account\u0026rsquo;s AWS services from other AWS accounts fail. This occurs even if you have granted the other accounts permission to access your account\u0026rsquo;s AWS services. If you reopen your AWS account, other AWS accounts can again access your account\u0026rsquo;s AWS services and resources if you granted the necessary permissions to the other AWS accounts.\nRemoving Amazon VPC peering connection AWS doesn\u0026rsquo;t delete Amazon Virtual Private Cloud (Amazon VPC) peering connections when you close one of the accounts participating in the VPC peering connection. Any traffic destined for the VPC peering connection originating from other active accounts is dropped because AWS terminates instances and deletes any security groups in the closed account. To remove the VPC peering connection, delete it from your account using the Amazon VPC console, AWS Command Line Interface (AWS CLI), or Amazon EC2 API. For more information, see Deleting a VPC Peering Connection.\nTroubleshooting errors when closing an AWS account If you receive an error message while trying to close your AWS account, you can contact your account representative or contact AWS Support to open a billing or account support case for assistance. Common reasons why you might not be able to close your AWS account include the following:\nYour account is the management account of an organization in AWS Organizations with active member accounts. To close the management account, you must first remove all member accounts from the organization.\nYou have unpaid invoices for your account.\nYou are not signed in to the account as the AWS account root user.\nYou are an active AWS Marketplace seller.\nHow to Close Your AWS Account Minimum Permissions To perform the following steps, you must have at least the following IAM permissions:\nYou must sign in as the AWS account root user, which requires no additional IAM permissions. You can\u0026rsquo;t perform these steps as an IAM user or role. Review Considerations before Closing Your AWS Account Sign in as the root user of the account you want to close, using the email address and password associated with the account. Note that signing in as an AWS Identity and Access Management (IAM) user or role will not allow you to close an account.\nOn the navigation bar in the upper-right corner, select your account name (or alias), and then choose \u0026ldquo;Account.\u0026rdquo;\nScroll to the end of the Account page to the \u0026ldquo;Close Account\u0026rdquo; section. Make sure you read and understand the text next to the check boxes. Once you close an AWS account, you will no longer have access to AWS services using that account.\nSelect the check boxes to accept the terms, and then choose \u0026ldquo;Close Account.\u0026rdquo;\nIn the confirmation box, choose \u0026ldquo;Close Account.\u0026rdquo;\nAccessing Your AWS Account after Closure After closing an AWS account, you will no longer have access to AWS services using that account. However, during the 90-day period following account closure (known as the Post-Closure Period), you can:\nView past billing information for your AWS account. Access AWS Support. During the Post-Closure Period, AWS may retain any content you didn\u0026rsquo;t delete and any active AWS services. To access remaining content or AWS services, you can reopen your account within the Post-Closure Period.\nReopening Your AWS Account To reopen your AWS account, contact AWS Support. If you choose to reopen your account, you can access retained content and AWS services that were active before account closure. Note that you might incur charges for running these AWS services during the Post-Closure Period. Use the AWS Pricing Calculator to estimate these costs.\nAfter the Post-Closure Period Once the Post-Closure Period ends, AWS permanently closes your AWS account. Any undeleted content will be permanently deleted, and any active AWS services will be stopped. Service attributes necessary for billing and administration purposes may be retained.\nPlease note that you cannot create a new AWS account using the same alias or email address that was registered to your closed AWS account.\nHow to Close Your AWS Account Minimum Permissions To perform the following steps, you must have at least the following IAM permissions:\nYou must sign in as the AWS account root user, which requires no additional IAM permissions. You can\u0026rsquo;t perform these steps as an IAM user or role. Review Considerations before Closing Your AWS Account Sign in as the root user of the account you want to close, using the email address and password associated with the account. Note that signing in as an AWS Identity and Access Management (IAM) user or role will not allow you to close an account.\nOn the navigation bar in the upper-right corner, select your account name (or alias), and then choose \u0026ldquo;Account.\u0026rdquo;\nScroll to the end of the Account page to the \u0026ldquo;Close Account\u0026rdquo; section. Make sure you read and understand the text next to the check boxes. Once you close an AWS account, you will no longer have access to AWS services using that account.\nSelect the check boxes to accept the terms, and then choose \u0026ldquo;Close Account.\u0026rdquo;\nIn the confirmation box, choose \u0026ldquo;Close Account.\u0026rdquo;\nAccessing Your AWS Account after Closure After closing an AWS account, you will no longer have access to AWS services using that account. However, during the 90-day period following account closure (known as the Post-Closure Period), you can:\nView past billing information for your AWS account. Access AWS Support. During the Post-Closure Period, AWS may retain any content you didn\u0026rsquo;t delete and any active AWS services. To access remaining content or AWS services, you can reopen your account within the Post-Closure Period.\nReopening Your AWS Account To reopen your AWS account, contact AWS Support. If you choose to reopen your account, you can access retained content and AWS services that were active before account closure. Note that you might incur charges for running these AWS services during the Post-Closure Period. Use the AWS Pricing Calculator to estimate these costs.\nAfter the Post-Closure Period Once the Post-Closure Period ends, AWS permanently closes your AWS account. Any undeleted content will be permanently deleted, and any active AWS services will be stopped. Service attributes necessary for billing and administration purposes may be retained.\nPlease note that you cannot create a new AWS account using the same alias or email address that was registered to your closed AWS account.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]